{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing dataset from dataset.csv\n",
      "Model loaded from best_val_model.npz\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cupy as cp\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "class ShallowNeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size, learning_rate=0.01, init_method='xavier'):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.beta1 = 0.9\n",
    "        self.beta2 = 0.999\n",
    "        self.epsilon = 1e-8\n",
    "        self.t = 0\n",
    "\n",
    "        self.W1, self.b1, self.W2, self.b2 = self.initialize_weights(init_method)\n",
    "        self.initialize_adam_parameters()\n",
    "\n",
    "    def initialize_adam_parameters(self):\n",
    "        self.mW1, self.vW1 = cp.zeros_like(self.W1), cp.zeros_like(self.W1)\n",
    "        self.mb1, self.vb1 = cp.zeros_like(self.b1), cp.zeros_like(self.b1)\n",
    "        self.mW2, self.vW2 = cp.zeros_like(self.W2), cp.zeros_like(self.W2)\n",
    "        self.mb2, self.vb2 = cp.zeros_like(self.b2), cp.zeros_like(self.b2)\n",
    "\n",
    "    def initialize_weights(self, method):\n",
    "        if method == 'xavier':\n",
    "            W1 = cp.random.randn(self.hidden_size, self.input_size) * cp.sqrt(1 / self.input_size)\n",
    "            W2 = cp.random.randn(self.output_size, self.hidden_size) * cp.sqrt(1 / self.hidden_size)\n",
    "        elif method == 'he':\n",
    "            W1 = cp.random.randn(self.hidden_size, self.input_size) * cp.sqrt(2 / self.input_size)\n",
    "            W2 = cp.random.randn(self.output_size, self.hidden_size) * cp.sqrt(2 / self.hidden_size)\n",
    "        else:\n",
    "            raise ValueError(\"init_method must be either 'xavier' or 'he'\")\n",
    "\n",
    "        b1 = cp.zeros((self.hidden_size, 1))\n",
    "        b2 = cp.zeros((self.output_size, 1))\n",
    "        return W1, b1, W2, b2\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.z1 = cp.dot(self.W1, x) + self.b1\n",
    "        self.a1 = cp.tanh(self.z1)\n",
    "        self.z2 = cp.dot(self.W2, self.a1) + self.b2\n",
    "        self.output = self.z2\n",
    "        return self.output\n",
    "\n",
    "    def predict(self, X):\n",
    "        self.forward(X)\n",
    "        return self.output\n",
    "\n",
    "    def load(self, file_path):\n",
    "        data = np.load(file_path)\n",
    "        self.W1 = cp.array(data['W1'])\n",
    "        self.b1 = cp.array(data['b1'])\n",
    "        self.W2 = cp.array(data['W2'])\n",
    "        self.b2 = cp.array(data['b2'])\n",
    "        print(f\"Model loaded from {file_path}\")\n",
    "def generate_data(num_samples=10000):\n",
    "    np.random.seed(42)\n",
    "    X = np.random.randint(1000, 10000, (num_samples, 2))\n",
    "    y = np.sum(X, axis=1).reshape(-1, 1)\n",
    "    return X, y\n",
    "\n",
    "def check_and_save_data(csv_path, num_samples):\n",
    "    if os.path.exists(csv_path):\n",
    "        print(f\"Loading existing dataset from {csv_path}\")\n",
    "        data = pd.read_csv(csv_path)\n",
    "        X = data[['x1', 'x2']].values\n",
    "        y = data['y'].values.reshape(-1, 1)\n",
    "    else:\n",
    "        print(f\"No existing dataset found. Generating new data...\")\n",
    "        X, y = generate_data(num_samples)\n",
    "        pd.DataFrame({'x1': X[:, 0], 'x2': X[:, 1], 'y': y.flatten()}).to_csv(csv_path, index=False)\n",
    "        print(f\"Dataset saved to {csv_path}\")\n",
    "    return X, y\n",
    "\n",
    "class Config:\n",
    "    EPOCHS = 100\n",
    "    BATCH_SIZE = pow(2, 4)\n",
    "    NUM_SAMPLES = pow(2, 14)\n",
    "    LEARNING_RATE = 0.001\n",
    "    MIN_RANGE = 1\n",
    "    MAX_RANGE = 20\n",
    "    HIDDEN_SIZES = range(MIN_RANGE, MAX_RANGE + 1)\n",
    "    ROUNDS = 30\n",
    "    PATIENCE = int(EPOCHS*0.1)\n",
    "    def __str__(self):\n",
    "        return (\n",
    "            f\"Config:\\n\"\n",
    "            f\"  LEARNING_RATE={self.LEARNING_RATE}\\n\"\n",
    "            f\"  EPOCHS={self.EPOCHS}\\n\"\n",
    "            f\"  BATCH_SIZE={self.BATCH_SIZE}\\n\"\n",
    "            f\"  NUM_SAMPLES={self.NUM_SAMPLES}\\n\"\n",
    "            f\"  MIN_RANGE={self.MIN_RANGE}\\n\"\n",
    "            f\"  MAX_RANGE={self.MAX_RANGE}\\n\"\n",
    "            f\"  HIDDEN_SIZES={list(self.HIDDEN_SIZES)}\\n\"\n",
    "            f\"  ROUNDS={self.ROUNDS}\\n\"\n",
    "            f\"  PATIENCE={self.PATIENCE}\\n\"\n",
    "            )\n",
    "\n",
    "config = Config()\n",
    "X, y = check_and_save_data('dataset.csv', config.NUM_SAMPLES)\n",
    "train_size = int(0.8 * X.shape[0])\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "scaler_X_0, scaler_X_1 = StandardScaler(), StandardScaler()\n",
    "X_train_0 = scaler_X_0.fit_transform(X_train[:, 0].reshape(-1, 1))\n",
    "X_train_1 = scaler_X_1.fit_transform(X_train[:, 1].reshape(-1, 1))\n",
    "X_train = np.hstack((X_train_0, X_train_1))\n",
    "\n",
    "X_test_0 = scaler_X_0.transform(X_test[:, 0].reshape(-1, 1))\n",
    "X_test_1 = scaler_X_1.transform(X_test[:, 1].reshape(-1, 1))\n",
    "X_test = np.hstack((X_test_0, X_test_1))\n",
    "\n",
    "scaler_y = StandardScaler()\n",
    "y_train = scaler_y.fit_transform(y_train.reshape(-1, 1))\n",
    "y_test = scaler_y.transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# 保存標準化器\n",
    "\n",
    "np.save('scaler_x0_mean.npy', scaler_X_0.mean_)\n",
    "np.save('scaler_x0_scale.npy', scaler_X_0.scale_)\n",
    "np.save('scaler_x1_mean.npy', scaler_X_1.mean_)\n",
    "np.save('scaler_x1_scale.npy', scaler_X_1.scale_)\n",
    "\n",
    "np.save('scaler_y_mean.npy', scaler_y.mean_)\n",
    "np.save('scaler_y_scale.npy', scaler_y.scale_)\n",
    "\n",
    "X_train_T = X_train.T\n",
    "y_train_T = y_train.reshape(1, -1)\n",
    "\n",
    "X_train = cp.array(X_train.T, dtype=cp.float32)\n",
    "X_test = cp.array(X_test.T, dtype=cp.float32)\n",
    "y_train = cp.array(y_train.T, dtype=cp.float32)\n",
    "y_test = cp.array(y_test.T, dtype=cp.float32)\n",
    "\n",
    "nn = ShallowNeuralNetwork(input_size=2, hidden_size=10, output_size=1, learning_rate=0.01, init_method='xavier')\n",
    "nn.load('best_val_model.npz')\n",
    "\n",
    "def calculate(input_x1, input_x2):\n",
    "    scaler_X_0 = StandardScaler()\n",
    "    scaler_X_1 = StandardScaler()\n",
    "    scaler_X_0.mean_ = np.load('scaler_x0_mean.npy')\n",
    "    scaler_X_0.scale_ = np.load('scaler_x0_scale.npy')\n",
    "    scaler_X_1.mean_ = np.load('scaler_x1_mean.npy')\n",
    "    scaler_X_1.scale_ = np.load('scaler_x1_scale.npy')\n",
    "\n",
    "    input_x1_scaled = scaler_X_0.transform(np.array([[input_x1]]))\n",
    "    input_x2_scaled = scaler_X_1.transform(np.array([[input_x2]]))\n",
    "    inputs = cp.array([[input_x1_scaled], [input_x2_scaled]], dtype=cp.float32).reshape(2, 1)\n",
    "\n",
    "    nn.forward(inputs)\n",
    "    output = nn.output.get()\n",
    "    \n",
    "    # 加載標準化器\n",
    "    scaler_y = StandardScaler()\n",
    "    scaler_y.mean_ = np.load('scaler_y_mean.npy')\n",
    "    scaler_y.scale_ = np.load('scaler_y_scale.npy')\n",
    "    \n",
    "    output_unscaled = scaler_y.inverse_transform(output)\n",
    "    return output_unscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9635 + 4382 = 14028.52\t(ideal: 14017)\n",
      "3214 + 4653 = 7867.20\t(ideal: 7867)\n",
      "7235 + 1472 = 8710.01\t(ideal: 8707)\n",
      "1000 + 1000 = 2108.21\t(ideal: 2000)\n",
      "9999 + 9999 = 19874.37\t(ideal: 19998)\n"
     ]
    }
   ],
   "source": [
    "def print_sum(x1, x2):\n",
    "    result = calculate(x1, x2)\n",
    "    print(f'{x1} + {x2} = {result.item():.2f}\\t(ideal: {x1+x2})')\n",
    "\n",
    "numbers = [(9635, 4382), (3214, 4653), (7235, 1472), (1000, 1000), (9999, 9999)]\n",
    "\n",
    "for x1, x2 in numbers:\n",
    "    print_sum(x1, x2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
