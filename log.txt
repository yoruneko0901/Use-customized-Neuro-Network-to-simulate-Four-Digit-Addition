2024-06-08 02:20:33,749 - INFO - No existing dataset found. Generating new data...
2024-06-08 02:20:33,761 - INFO - Dataset saved to dataset.csv
2024-06-08 02:20:33,840 - INFO - Config:
  LEARNING_RATE=0.001
  EPOCHS=10
  BATCH_SIZE=16
  NUM_SAMPLES=16384
  MIN_RANGE=1
  MAX_RANGE=20
  HIDDEN_SIZES=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]
  ROUNDS=30
  PATIENCE=1

2024-06-08 02:20:33,841 - INFO - ----Hidden_size 1:
2024-06-08 02:20:33,841 - INFO - Round(1/30)
2024-06-08 02:20:45,409 - INFO - >>training completed		| train loss=0.005934775404577208, val loss=0.00545298146725758
2024-06-08 02:20:45,419 - INFO - Model saved to best_val_model.npz
2024-06-08 02:20:45,420 - INFO - Model saved to best_train_model.npz
2024-06-08 02:20:45,420 - INFO - Round(2/30)
2024-06-08 02:20:56,138 - INFO - >>training completed		| train loss=0.005952430635343927, val loss=0.005469327029459592
2024-06-08 02:20:56,138 - INFO - Round(3/30)
2024-06-08 02:21:06,965 - INFO - >>training completed		| train loss=0.004704688115066484, val loss=0.004321356827589181
2024-06-08 02:21:06,966 - INFO - Model saved to best_val_model.npz
2024-06-08 02:21:06,966 - INFO - Model saved to best_train_model.npz
2024-06-08 02:21:06,966 - INFO - Round(4/30)
2024-06-08 02:21:18,333 - INFO - >>training completed		| train loss=0.003075015290899885, val loss=0.002824260464771928
2024-06-08 02:21:18,334 - INFO - Model saved to best_val_model.npz
2024-06-08 02:21:18,334 - INFO - Model saved to best_train_model.npz
2024-06-08 02:21:18,334 - INFO - Round(5/30)
2024-06-08 02:21:29,854 - INFO - >>training completed		| train loss=0.0030827373192561774, val loss=0.002831732390352415
2024-06-08 02:21:29,854 - INFO - Round(6/30)
2024-06-08 02:21:40,538 - INFO - >>training completed		| train loss=0.0022910338948498457, val loss=0.0021047813448515254
2024-06-08 02:21:40,539 - INFO - Model saved to best_val_model.npz
2024-06-08 02:21:40,539 - INFO - Model saved to best_train_model.npz
2024-06-08 02:21:40,539 - INFO - Round(7/30)
2024-06-08 02:21:51,199 - INFO - >>training completed		| train loss=0.0041646852856546315, val loss=0.003825177830710983
2024-06-08 02:21:51,200 - INFO - Round(8/30)
2024-06-08 02:22:02,395 - INFO - >>training completed		| train loss=0.004007173773539653, val loss=0.0036803693515893377
2024-06-08 02:22:02,395 - INFO - Round(9/30)
2024-06-08 02:22:13,272 - INFO - >>training completed		| train loss=0.004882858318478458, val loss=0.0044850807537593325
2024-06-08 02:22:13,272 - INFO - Round(10/30)
2024-06-08 02:22:23,861 - INFO - >>training completed		| train loss=0.003040445501388941, val loss=0.002793009979722656
2024-06-08 02:22:23,862 - INFO - Round(11/30)
2024-06-08 02:22:34,560 - INFO - >>training completed		| train loss=0.005277269050547951, val loss=0.004847900693521661
2024-06-08 02:22:34,560 - INFO - Round(12/30)
2024-06-08 02:22:45,412 - INFO - >>training completed		| train loss=0.003290523275425535, val loss=0.0030225719524356355
2024-06-08 02:22:45,412 - INFO - Round(13/30)
2024-06-08 02:22:56,849 - INFO - >>training completed		| train loss=0.0012911061987897173, val loss=0.0011833823461408562
2024-06-08 02:22:56,850 - INFO - Model saved to best_val_model.npz
2024-06-08 02:22:56,851 - INFO - Model saved to best_train_model.npz
2024-06-08 02:22:56,851 - INFO - Round(14/30)
2024-06-08 02:23:07,974 - INFO - >>training completed		| train loss=0.006745204124391865, val loss=0.006199709508990155
2024-06-08 02:23:07,974 - INFO - Round(15/30)
2024-06-08 02:23:18,570 - INFO - >>training completed		| train loss=0.005211387591260435, val loss=0.004789323268955498
2024-06-08 02:23:18,570 - INFO - Round(16/30)
2024-06-08 02:23:29,014 - INFO - >>training completed		| train loss=0.003944668689718071, val loss=0.003622928023777162
2024-06-08 02:23:29,015 - INFO - Round(17/30)
2024-06-08 02:23:39,490 - INFO - >>training completed		| train loss=0.001250247222842647, val loss=0.0011456294770933225
2024-06-08 02:23:39,490 - INFO - Model saved to best_val_model.npz
2024-06-08 02:23:39,491 - INFO - Model saved to best_train_model.npz
2024-06-08 02:23:39,491 - INFO - Round(18/30)
2024-06-08 02:23:49,874 - INFO - >>training completed		| train loss=0.0052668166876898, val loss=0.004838292381726718
2024-06-08 02:23:49,874 - INFO - Round(19/30)
2024-06-08 02:24:00,244 - INFO - >>training completed		| train loss=0.007407025789723866, val loss=0.006810474680153004
2024-06-08 02:24:00,244 - INFO - Round(20/30)
2024-06-08 02:24:10,619 - INFO - >>training completed		| train loss=0.003806497801567006, val loss=0.003496225456960166
2024-06-08 02:24:10,620 - INFO - Round(21/30)
2024-06-08 02:24:21,653 - INFO - >>training completed		| train loss=0.004032467956751626, val loss=0.0037037382335806013
2024-06-08 02:24:21,653 - INFO - Round(22/30)
2024-06-08 02:24:32,918 - INFO - >>training completed		| train loss=0.0021479874576695633, val loss=0.0019728597773987695
2024-06-08 02:24:32,918 - INFO - Round(23/30)
2024-06-08 02:24:43,648 - INFO - >>training completed		| train loss=0.007480565165511679, val loss=0.0068788952533709435
2024-06-08 02:24:43,648 - INFO - Round(24/30)
2024-06-08 02:24:54,417 - INFO - >>training completed		| train loss=0.003252910340885975, val loss=0.0029879856044674217
2024-06-08 02:24:54,417 - INFO - Round(25/30)
2024-06-08 02:25:05,323 - INFO - >>training completed		| train loss=0.006084965110026289, val loss=0.005591926918799583
2024-06-08 02:25:05,324 - INFO - Round(26/30)
2024-06-08 02:25:16,158 - INFO - >>training completed		| train loss=0.0042883503562007215, val loss=0.003938776102750101
2024-06-08 02:25:16,158 - INFO - Round(27/30)
2024-06-08 02:25:27,112 - INFO - >>training completed		| train loss=0.0028676294079197986, val loss=0.002634370283519909
2024-06-08 02:25:27,112 - INFO - Round(28/30)
2024-06-08 02:25:37,693 - INFO - >>training completed		| train loss=0.0023979957416167623, val loss=0.002203096508392643
2024-06-08 02:25:37,693 - INFO - Round(29/30)
2024-06-08 02:25:48,458 - INFO - >>training completed		| train loss=0.0033666091939831494, val loss=0.003092411528179179
2024-06-08 02:25:48,458 - INFO - Round(30/30)
2024-06-08 02:25:59,339 - INFO - >>training completed		| train loss=0.0038995787985676824, val loss=0.0035815029616453435
2024-06-08 02:25:59,339 - INFO - #目前最低損失: train=0.001250247222842647, val=0.0011456294770933225
2024-06-08 02:25:59,339 - INFO - #目前最佳隱藏層神經元數量: train=1, val=1
2024-06-08 02:25:59,340 - INFO - #目前最佳參數:
-train:
W1=[[0.19966308 0.19976896]]
b1=[[-0.00144171]]
W2=[[3.72457387]]
b2=[[0.00311631]]
-val:
W1=[[0.19966308 0.19976896]]
b1=[[-0.00144171]]
W2=[[3.72457387]]
b2=[[0.00311631]]

2024-06-08 02:25:59,340 - INFO - ----Hidden_size 2:
2024-06-08 02:25:59,340 - INFO - Round(1/30)
2024-06-08 02:26:10,519 - INFO - >>training completed		| train loss=0.0013769518634829169, val loss=0.0012762151400701758
2024-06-08 02:26:10,520 - INFO - Round(2/30)
2024-06-08 02:26:20,805 - INFO - >>training completed		| train loss=0.0018792372502428828, val loss=0.0017379139002391597
2024-06-08 02:26:20,805 - INFO - Round(3/30)
2024-06-08 02:26:31,174 - INFO - >>training completed		| train loss=0.0007346933472733165, val loss=0.0006786470001392943
2024-06-08 02:26:31,174 - INFO - Model saved to best_val_model.npz
2024-06-08 02:26:31,175 - INFO - Model saved to best_train_model.npz
2024-06-08 02:26:31,175 - INFO - Round(4/30)
2024-06-08 02:26:41,866 - INFO - >>training completed		| train loss=0.0013002688995352866, val loss=0.0012040910550572019
2024-06-08 02:26:41,866 - INFO - Round(5/30)
2024-06-08 02:26:52,409 - INFO - >>training completed		| train loss=0.0012560121303747602, val loss=0.0011628439011043248
2024-06-08 02:26:52,410 - INFO - Round(6/30)
2024-06-08 02:27:03,198 - INFO - >>training completed		| train loss=0.0015423200720284468, val loss=0.0014270979311550866
2024-06-08 02:27:03,198 - INFO - Round(7/30)
2024-06-08 02:27:13,716 - INFO - >>training completed		| train loss=0.0011714969205669397, val loss=0.0010820627761277892
2024-06-08 02:27:13,716 - INFO - Round(8/30)
2024-06-08 02:27:24,207 - INFO - >>training completed		| train loss=0.0013509483306864492, val loss=0.0012508423722162841
2024-06-08 02:27:24,207 - INFO - Round(9/30)
2024-06-08 02:27:34,810 - INFO - >>training completed		| train loss=0.0019890565302356617, val loss=0.0018402812151605684
2024-06-08 02:27:34,810 - INFO - Round(10/30)
2024-06-08 02:27:45,073 - INFO - >>training completed		| train loss=0.001887596297705377, val loss=0.0017460885848503062
2024-06-08 02:27:45,073 - INFO - Round(11/30)
2024-06-08 02:27:55,241 - INFO - >>training completed		| train loss=0.0018826130379326277, val loss=0.001744936664329636
2024-06-08 02:27:55,241 - INFO - Round(12/30)
2024-06-08 02:28:05,466 - INFO - >>training completed		| train loss=0.0018944254953409212, val loss=0.0017515539239473124
2024-06-08 02:28:05,466 - INFO - Round(13/30)
2024-06-08 02:28:15,663 - INFO - >>training completed		| train loss=0.0016429007871584336, val loss=0.0015207867108969965
2024-06-08 02:28:15,664 - INFO - Round(14/30)
2024-06-08 02:28:26,093 - INFO - >>training completed		| train loss=0.0018937277581668648, val loss=0.0017527406449889236
2024-06-08 02:28:26,093 - INFO - Round(15/30)
2024-06-08 02:28:36,445 - INFO - >>training completed		| train loss=0.001336350942020993, val loss=0.0012376137976426306
2024-06-08 02:28:36,445 - INFO - Round(16/30)
2024-06-08 02:28:46,538 - INFO - >>training completed		| train loss=0.0010962485897262268, val loss=0.0010145183051651757
2024-06-08 02:28:46,538 - INFO - Round(17/30)
2024-06-08 02:28:57,242 - INFO - >>training completed		| train loss=0.0029134719893045263, val loss=0.0026869569696083857
2024-06-08 02:28:57,242 - INFO - Round(18/30)
2024-06-08 02:29:07,734 - INFO - >>training completed		| train loss=0.0014453247966463162, val loss=0.0013384747125407515
2024-06-08 02:29:07,734 - INFO - Round(19/30)
2024-06-08 02:29:18,022 - INFO - >>training completed		| train loss=0.001184959568815033, val loss=0.0010970023599405025
2024-06-08 02:29:18,023 - INFO - Round(20/30)
2024-06-08 02:29:28,302 - INFO - >>training completed		| train loss=0.0010257353611236443, val loss=0.0009491512709658474
2024-06-08 02:29:28,302 - INFO - Round(21/30)
2024-06-08 02:29:38,600 - INFO - >>training completed		| train loss=0.0018860140646646967, val loss=0.0017446489838827078
2024-06-08 02:29:38,600 - INFO - Round(22/30)
2024-06-08 02:29:48,940 - INFO - >>training completed		| train loss=0.001290031477498943, val loss=0.0011944665502188203
2024-06-08 02:29:48,940 - INFO - Round(23/30)
2024-06-08 02:29:59,266 - INFO - >>training completed		| train loss=0.001267592903043297, val loss=0.0011741837196301923
2024-06-08 02:29:59,266 - INFO - Round(24/30)
2024-06-08 02:30:09,701 - INFO - >>training completed		| train loss=0.0019459563282502514, val loss=0.0017990662876432569
2024-06-08 02:30:09,701 - INFO - Round(25/30)
2024-06-08 02:30:20,645 - INFO - >>training completed		| train loss=0.0013076003184742798, val loss=0.0012109281268676967
2024-06-08 02:30:20,645 - INFO - Round(26/30)
2024-06-08 02:30:32,157 - INFO - >>training completed		| train loss=0.00199417674252762, val loss=0.0018431677135520594
2024-06-08 02:30:32,157 - INFO - Round(27/30)
2024-06-08 02:30:42,757 - INFO - >>training completed		| train loss=0.0011029763970098055, val loss=0.0010208966941918827
2024-06-08 02:30:42,757 - INFO - Round(28/30)
2024-06-08 02:30:52,946 - INFO - >>training completed		| train loss=0.0012383279491101678, val loss=0.0011465071908853296
2024-06-08 02:30:52,946 - INFO - Round(29/30)
2024-06-08 02:31:03,516 - INFO - >>training completed		| train loss=0.0018006060863069244, val loss=0.0016668201693364724
2024-06-08 02:31:03,516 - INFO - Round(30/30)
2024-06-08 02:31:13,787 - INFO - >>training completed		| train loss=0.002336040997876849, val loss=0.0021575734258437768
2024-06-08 02:31:13,787 - INFO - #目前最低損失: train=0.0007346933472733165, val=0.0006786470001392943
2024-06-08 02:31:13,787 - INFO - #目前最佳隱藏層神經元數量: train=2, val=2
2024-06-08 02:31:13,788 - INFO - #目前最佳參數:
-train:
W1=[[-0.26076103 -0.1095076 ]
 [ 0.02757774  0.36425581]]
b1=[[ 0.00147028]
 [-0.00030967]]
W2=[[-2.70861499  1.26639922]]
b2=[[0.00300226]]
-val:
W1=[[-0.26076103 -0.1095076 ]
 [ 0.02757774  0.36425581]]
b1=[[ 0.00147028]
 [-0.00030967]]
W2=[[-2.70861499  1.26639922]]
b2=[[0.00300226]]

2024-06-08 02:31:13,789 - INFO - ----Hidden_size 3:
2024-06-08 02:31:13,789 - INFO - Round(1/30)
2024-06-08 02:31:24,006 - INFO - >>training completed		| train loss=0.0008332360312094465, val loss=0.0007719650048019117
2024-06-08 02:31:24,007 - INFO - Round(2/30)
2024-06-08 02:31:34,316 - INFO - >>training completed		| train loss=0.00101490780306749, val loss=0.0009402318899100428
2024-06-08 02:31:34,316 - INFO - Round(3/30)
2024-06-08 02:31:44,573 - INFO - >>training completed		| train loss=0.0015864341553858434, val loss=0.0014772302622493827
2024-06-08 02:31:44,573 - INFO - Round(4/30)
2024-06-08 02:31:54,892 - INFO - >>training completed		| train loss=0.0011770459169911645, val loss=0.0010899940445618544
2024-06-08 02:31:54,893 - INFO - Round(5/30)
2024-06-08 02:32:05,172 - INFO - >>training completed		| train loss=0.0021502787684989644, val loss=0.0019907281008075487
2024-06-08 02:32:05,172 - INFO - Round(6/30)
2024-06-08 02:32:15,458 - INFO - >>training completed		| train loss=0.0007715429296821559, val loss=0.0007150456810465117
2024-06-08 02:32:15,458 - INFO - Round(7/30)
2024-06-08 02:32:27,142 - INFO - >>training completed		| train loss=0.0009941038158577259, val loss=0.0009272032978027688
2024-06-08 02:32:27,142 - INFO - Round(8/30)
2024-06-08 02:32:39,131 - INFO - >>training completed		| train loss=0.0008804558555340765, val loss=0.0008157097873027231
2024-06-08 02:32:39,132 - INFO - Round(9/30)
2024-06-08 02:32:49,559 - INFO - >>training completed		| train loss=0.0010888239795967356, val loss=0.001010120030956339
2024-06-08 02:32:49,559 - INFO - Round(10/30)
2024-06-08 02:33:00,078 - INFO - >>training completed		| train loss=0.0006528002874991711, val loss=0.0006053557203290143
2024-06-08 02:33:00,079 - INFO - Model saved to best_val_model.npz
2024-06-08 02:33:00,080 - INFO - Model saved to best_train_model.npz
2024-06-08 02:33:00,080 - INFO - Round(11/30)
2024-06-08 02:33:10,553 - INFO - >>training completed		| train loss=0.001063100526808343, val loss=0.0009925591292895678
2024-06-08 02:33:10,554 - INFO - Round(12/30)
2024-06-08 02:33:21,181 - INFO - >>training completed		| train loss=0.0012893183227439722, val loss=0.0011946824304864105
2024-06-08 02:33:21,181 - INFO - Round(13/30)
2024-06-08 02:33:32,169 - INFO - >>training completed		| train loss=0.00120984052253753, val loss=0.0011198755314384906
2024-06-08 02:33:32,169 - INFO - Round(14/30)
2024-06-08 02:33:43,360 - INFO - >>training completed		| train loss=0.0015055970930286328, val loss=0.0013968907007797851
2024-06-08 02:33:43,360 - INFO - Round(15/30)
2024-06-08 02:33:54,617 - INFO - >>training completed		| train loss=0.00040645432633641015, val loss=0.00037844970755409246
2024-06-08 02:33:54,618 - INFO - Model saved to best_val_model.npz
2024-06-08 02:33:54,618 - INFO - Model saved to best_train_model.npz
2024-06-08 02:33:54,619 - INFO - Round(16/30)
2024-06-08 02:34:05,684 - INFO - >>training completed		| train loss=0.0007980215617017956, val loss=0.000738791777857237
2024-06-08 02:34:05,684 - INFO - Round(17/30)
2024-06-08 02:34:17,151 - INFO - >>training completed		| train loss=0.0015503683245060578, val loss=0.0014369616390952755
2024-06-08 02:34:17,151 - INFO - Round(18/30)
2024-06-08 02:34:27,580 - INFO - >>training completed		| train loss=0.0015491366224742258, val loss=0.0014350913256866151
2024-06-08 02:34:27,580 - INFO - Round(19/30)
2024-06-08 02:34:38,164 - INFO - >>training completed		| train loss=0.00035533238376992977, val loss=0.00033017245391139073
2024-06-08 02:34:38,165 - INFO - Model saved to best_val_model.npz
2024-06-08 02:34:38,165 - INFO - Model saved to best_train_model.npz
2024-06-08 02:34:38,166 - INFO - Round(20/30)
2024-06-08 02:34:49,220 - INFO - >>training completed		| train loss=0.001047112715163933, val loss=0.0009690570888603721
2024-06-08 02:34:49,220 - INFO - Round(21/30)
2024-06-08 02:34:59,672 - INFO - >>training completed		| train loss=0.0018631234046456496, val loss=0.0017278253644934611
2024-06-08 02:34:59,673 - INFO - Round(22/30)
2024-06-08 02:35:10,164 - INFO - >>training completed		| train loss=0.000878855212770954, val loss=0.0008136909974896298
2024-06-08 02:35:10,164 - INFO - Round(23/30)
2024-06-08 02:35:20,569 - INFO - >>training completed		| train loss=0.000558139743613395, val loss=0.0005178957831162562
2024-06-08 02:35:20,569 - INFO - Round(24/30)
2024-06-08 02:35:31,095 - INFO - >>training completed		| train loss=0.001095683588949202, val loss=0.0010268303297766713
2024-06-08 02:35:31,095 - INFO - Round(25/30)
2024-06-08 02:35:41,483 - INFO - >>training completed		| train loss=0.0009729378244787991, val loss=0.00090111593060272
2024-06-08 02:35:41,483 - INFO - Round(26/30)
2024-06-08 02:35:51,884 - INFO - >>training completed		| train loss=0.001339125464089584, val loss=0.0012408748904236182
2024-06-08 02:35:51,884 - INFO - Round(27/30)
2024-06-08 02:36:02,342 - INFO - >>training completed		| train loss=0.000931638919343349, val loss=0.0008633846591386804
2024-06-08 02:36:02,342 - INFO - Round(28/30)
2024-06-08 02:36:12,740 - INFO - >>training completed		| train loss=0.0008736559399815575, val loss=0.00081336921319145
2024-06-08 02:36:12,740 - INFO - Round(29/30)
2024-06-08 02:36:23,278 - INFO - >>training completed		| train loss=0.0016028634724885016, val loss=0.0014860776164387552
2024-06-08 02:36:23,278 - INFO - Round(30/30)
2024-06-08 02:36:33,779 - INFO - >>training completed		| train loss=0.0012999248188640597, val loss=0.0012051475714126762
2024-06-08 02:36:33,779 - INFO - #目前最低損失: train=0.00035533238376992977, val=0.00033017245391139073
2024-06-08 02:36:33,779 - INFO - #目前最佳隱藏層神經元數量: train=3, val=3
2024-06-08 02:36:33,779 - INFO - #目前最佳參數:
-train:
W1=[[0.30788957 0.15729364]
 [0.93364794 0.94625121]
 [0.19841293 0.27597273]]
b1=[[-0.00424611]
 [-0.00420991]
 [-0.00045406]]
W2=[[ 1.25692125 -0.2101459   2.4701129 ]]
b2=[[0.00343671]]
-val:
W1=[[0.30788957 0.15729364]
 [0.93364794 0.94625121]
 [0.19841293 0.27597273]]
b1=[[-0.00424611]
 [-0.00420991]
 [-0.00045406]]
W2=[[ 1.25692125 -0.2101459   2.4701129 ]]
b2=[[0.00343671]]

2024-06-08 02:36:33,780 - INFO - ----Hidden_size 4:
2024-06-08 02:36:33,780 - INFO - Round(1/30)
2024-06-08 02:36:44,219 - INFO - >>training completed		| train loss=0.000342070401467695, val loss=0.00031832466829431896
2024-06-08 02:36:44,220 - INFO - Model saved to best_val_model.npz
2024-06-08 02:36:44,221 - INFO - Model saved to best_train_model.npz
2024-06-08 02:36:44,221 - INFO - Round(2/30)
2024-06-08 02:36:54,690 - INFO - >>training completed		| train loss=0.001294667063524646, val loss=0.0012525204525364818
2024-06-08 02:36:54,690 - INFO - Round(3/30)
2024-06-08 02:37:05,047 - INFO - >>training completed		| train loss=0.0007620282692104814, val loss=0.0007055802474014792
2024-06-08 02:37:05,047 - INFO - Round(4/30)
2024-06-08 02:37:15,531 - INFO - >>training completed		| train loss=0.0006738009601843053, val loss=0.0006267632162142269
2024-06-08 02:37:15,531 - INFO - Round(5/30)
2024-06-08 02:37:26,000 - INFO - >>training completed		| train loss=0.0007609811372393359, val loss=0.0007059754225066982
2024-06-08 02:37:26,000 - INFO - Round(6/30)
2024-06-08 02:37:36,404 - INFO - >>training completed		| train loss=0.0004095016210789774, val loss=0.0003845845022355935
2024-06-08 02:37:36,404 - INFO - Round(7/30)
2024-06-08 02:37:46,847 - INFO - >>training completed		| train loss=0.0007342042778525442, val loss=0.0006823834457441356
2024-06-08 02:37:46,847 - INFO - Round(8/30)
2024-06-08 02:37:57,241 - INFO - >>training completed		| train loss=0.0007420188904434375, val loss=0.0006897020746984029
2024-06-08 02:37:57,241 - INFO - Round(9/30)
2024-06-08 02:38:07,665 - INFO - >>training completed		| train loss=0.00048561403878005777, val loss=0.0004525326167143345
2024-06-08 02:38:07,665 - INFO - Round(10/30)
2024-06-08 02:38:18,050 - INFO - >>training completed		| train loss=0.00046776189133347764, val loss=0.00043558431363463696
2024-06-08 02:38:18,050 - INFO - Round(11/30)
2024-06-08 02:38:28,544 - INFO - >>training completed		| train loss=0.0007627748382887088, val loss=0.0007065024254884916
2024-06-08 02:38:28,544 - INFO - Round(12/30)
2024-06-08 02:38:39,059 - INFO - >>training completed		| train loss=0.0016519700298591902, val loss=0.0015330661974678216
2024-06-08 02:38:39,059 - INFO - Round(13/30)
2024-06-08 02:38:50,021 - INFO - >>training completed		| train loss=0.0006584002073617742, val loss=0.0006122035201625458
2024-06-08 02:38:50,022 - INFO - Round(14/30)
2024-06-08 02:39:00,788 - INFO - >>training completed		| train loss=0.0004808197263996453, val loss=0.0004476566025550677
2024-06-08 02:39:00,788 - INFO - Round(15/30)
2024-06-08 02:39:11,415 - INFO - >>training completed		| train loss=0.0006010739420782164, val loss=0.0005588795393552482
2024-06-08 02:39:11,416 - INFO - Round(16/30)
2024-06-08 02:39:22,033 - INFO - >>training completed		| train loss=0.0007127984873446795, val loss=0.000666071355661044
2024-06-08 02:39:22,033 - INFO - Round(17/30)
2024-06-08 02:39:32,562 - INFO - >>training completed		| train loss=0.00047020597831922567, val loss=0.0004554698649954075
2024-06-08 02:39:32,562 - INFO - Round(18/30)
2024-06-08 02:39:43,065 - INFO - >>training completed		| train loss=0.0006905244656880021, val loss=0.0006405724028488421
2024-06-08 02:39:43,065 - INFO - Round(19/30)
2024-06-08 02:39:53,804 - INFO - >>training completed		| train loss=0.00077487124002491, val loss=0.0007302581217043695
2024-06-08 02:39:53,804 - INFO - Round(20/30)
2024-06-08 02:40:04,333 - INFO - >>training completed		| train loss=0.0007502297363151471, val loss=0.0006981796045146159
2024-06-08 02:40:04,333 - INFO - Round(21/30)
2024-06-08 02:40:15,169 - INFO - >>training completed		| train loss=0.00037605544337003695, val loss=0.00035068246356734846
2024-06-08 02:40:15,170 - INFO - Round(22/30)
2024-06-08 02:40:25,642 - INFO - >>training completed		| train loss=0.0006776457492819981, val loss=0.0006284519240753164
2024-06-08 02:40:25,642 - INFO - Round(23/30)
2024-06-08 02:40:36,045 - INFO - >>training completed		| train loss=0.000890863269560614, val loss=0.0008293798636831628
2024-06-08 02:40:36,046 - INFO - Round(24/30)
2024-06-08 02:40:46,449 - INFO - >>training completed		| train loss=0.0006881583144161757, val loss=0.0006375011879737509
2024-06-08 02:40:46,449 - INFO - Round(25/30)
2024-06-08 02:40:56,938 - INFO - >>training completed		| train loss=0.0005466341505580635, val loss=0.0005229991195201271
2024-06-08 02:40:56,938 - INFO - Round(26/30)
2024-06-08 02:41:07,634 - INFO - >>training completed		| train loss=0.0006441481235688552, val loss=0.0006085881526860449
2024-06-08 02:41:07,634 - INFO - Round(27/30)
2024-06-08 02:41:18,536 - INFO - >>training completed		| train loss=0.0013687621204284104, val loss=0.001268368010083227
2024-06-08 02:41:18,536 - INFO - Round(28/30)
2024-06-08 02:41:29,166 - INFO - >>training completed		| train loss=0.0010081877289593083, val loss=0.0009325438288482049
2024-06-08 02:41:29,166 - INFO - Round(29/30)
2024-06-08 02:41:39,671 - INFO - >>training completed		| train loss=0.001420161872753283, val loss=0.0013508243764032584
2024-06-08 02:41:39,671 - INFO - Round(30/30)
2024-06-08 02:41:50,217 - INFO - >>training completed		| train loss=0.00042898579871819884, val loss=0.00041409724562458175
2024-06-08 02:41:50,217 - INFO - #目前最低損失: train=0.000342070401467695, val=0.00031832466829431896
2024-06-08 02:41:50,217 - INFO - #目前最佳隱藏層神經元數量: train=4, val=4
2024-06-08 02:41:50,218 - INFO - #目前最佳參數:
-train:
W1=[[-0.29088747 -0.01954112]
 [ 0.22078031  0.09249363]
 [-0.13536749 -0.17865703]
 [-0.02956763 -0.28102486]]
b1=[[ 0.00203831]
 [-0.00320682]
 [-0.00170268]
 [ 0.00145274]]
W2=[[-1.18782761  0.96809854 -0.9828277  -1.60472439]]
b2=[[0.00265259]]
-val:
W1=[[-0.29088747 -0.01954112]
 [ 0.22078031  0.09249363]
 [-0.13536749 -0.17865703]
 [-0.02956763 -0.28102486]]
b1=[[ 0.00203831]
 [-0.00320682]
 [-0.00170268]
 [ 0.00145274]]
W2=[[-1.18782761  0.96809854 -0.9828277  -1.60472439]]
b2=[[0.00265259]]

2024-06-08 02:41:50,219 - INFO - ----Hidden_size 5:
2024-06-08 02:41:50,219 - INFO - Round(1/30)
2024-06-08 02:42:00,955 - INFO - >>training completed		| train loss=0.0009237391018533228, val loss=0.0008692242452427784
2024-06-08 02:42:00,956 - INFO - Round(2/30)
2024-06-08 02:42:11,707 - INFO - >>training completed		| train loss=0.0005181853977079699, val loss=0.0005037824308844768
2024-06-08 02:42:11,707 - INFO - Round(3/30)
2024-06-08 02:42:22,347 - INFO - >>training completed		| train loss=0.0005056262191228617, val loss=0.0004727284062933416
2024-06-08 02:42:22,347 - INFO - Round(4/30)
2024-06-08 02:42:33,132 - INFO - >>training completed		| train loss=0.0007910175560892742, val loss=0.0007472274335323295
2024-06-08 02:42:33,132 - INFO - Round(5/30)
2024-06-08 02:42:43,812 - INFO - >>training completed		| train loss=0.0006372375538562123, val loss=0.0005982730737965946
2024-06-08 02:42:43,812 - INFO - Round(6/30)
2024-06-08 02:42:54,598 - INFO - >>training completed		| train loss=0.0006582885163127077, val loss=0.0006120942164682781
2024-06-08 02:42:54,598 - INFO - Round(7/30)
2024-06-08 02:43:05,035 - INFO - >>training completed		| train loss=0.0006237354473741937, val loss=0.00058087343202068
2024-06-08 02:43:05,035 - INFO - Round(8/30)
2024-06-08 02:43:15,575 - INFO - >>training completed		| train loss=0.0007921341289831323, val loss=0.0007431685044230366
2024-06-08 02:43:15,576 - INFO - Round(9/30)
2024-06-08 02:43:26,157 - INFO - >>training completed		| train loss=0.0006041171151176304, val loss=0.0005636412786047192
2024-06-08 02:43:26,157 - INFO - Round(10/30)
2024-06-08 02:43:36,730 - INFO - >>training completed		| train loss=0.0009846308492545437, val loss=0.0009191809454534487
2024-06-08 02:43:36,730 - INFO - Round(11/30)
2024-06-08 02:43:47,251 - INFO - >>training completed		| train loss=0.0005340722978576358, val loss=0.0004984318195997532
2024-06-08 02:43:47,251 - INFO - Round(12/30)
2024-06-08 02:43:58,056 - INFO - >>training completed		| train loss=0.0007887717485249784, val loss=0.0007321119226182013
2024-06-08 02:43:58,056 - INFO - Round(13/30)
2024-06-08 02:44:08,565 - INFO - >>training completed		| train loss=0.00039966232245188617, val loss=0.0003746960907659271
2024-06-08 02:44:08,565 - INFO - Round(14/30)
2024-06-08 02:44:19,651 - INFO - >>training completed		| train loss=0.00032619275950129773, val loss=0.0003187206440632519
2024-06-08 02:44:19,652 - INFO - Model saved to best_train_model.npz
2024-06-08 02:44:19,652 - INFO - Round(15/30)
2024-06-08 02:44:30,448 - INFO - >>training completed		| train loss=0.00047094295696945834, val loss=0.00043959344133482394
2024-06-08 02:44:30,448 - INFO - Round(16/30)
2024-06-08 02:44:41,660 - INFO - >>training completed		| train loss=0.0006262781457906476, val loss=0.0005830812055179138
2024-06-08 02:44:41,661 - INFO - Round(17/30)
2024-06-08 02:44:52,320 - INFO - >>training completed		| train loss=0.0008953950532508643, val loss=0.0008422595461600475
2024-06-08 02:44:52,320 - INFO - Round(18/30)
2024-06-08 02:45:03,010 - INFO - >>training completed		| train loss=0.0014086668903549402, val loss=0.0013467538178515033
2024-06-08 02:45:03,010 - INFO - Round(19/30)
2024-06-08 02:45:13,709 - INFO - >>training completed		| train loss=0.001035306748089391, val loss=0.0010018096044859014
2024-06-08 02:45:13,709 - INFO - Round(20/30)
2024-06-08 02:45:24,648 - INFO - >>training completed		| train loss=0.0007535856780991651, val loss=0.0007030826888224224
2024-06-08 02:45:24,648 - INFO - Round(21/30)
2024-06-08 02:45:35,398 - INFO - >>training completed		| train loss=0.0008748285881915716, val loss=0.0008203702321445056
2024-06-08 02:45:35,398 - INFO - Round(22/30)
2024-06-08 02:45:46,386 - INFO - >>training completed		| train loss=0.0006621557647803762, val loss=0.000618125370800045
2024-06-08 02:45:46,386 - INFO - Round(23/30)
2024-06-08 02:45:57,172 - INFO - >>training completed		| train loss=0.0014977016446520261, val loss=0.0014376886138808241
2024-06-08 02:45:57,172 - INFO - Round(24/30)
2024-06-08 02:46:08,388 - INFO - >>training completed		| train loss=0.0006166531458144421, val loss=0.0005780286502135998
2024-06-08 02:46:08,388 - INFO - Round(25/30)
2024-06-08 02:46:19,266 - INFO - >>training completed		| train loss=0.0006890090672071168, val loss=0.0006431367090688774
2024-06-08 02:46:19,267 - INFO - Round(26/30)
2024-06-08 02:46:30,104 - INFO - >>training completed		| train loss=0.0008046293355009487, val loss=0.0007733239686561787
2024-06-08 02:46:30,105 - INFO - Round(27/30)
2024-06-08 02:46:41,093 - INFO - >>training completed		| train loss=0.0008381884149003641, val loss=0.0007908867047827604
2024-06-08 02:46:41,093 - INFO - Round(28/30)
2024-06-08 02:46:51,943 - INFO - >>training completed		| train loss=0.0010735291822812376, val loss=0.00101255213951592
2024-06-08 02:46:51,943 - INFO - Round(29/30)
2024-06-08 02:47:03,017 - INFO - >>training completed		| train loss=0.0005980683370714728, val loss=0.000556964886597008
2024-06-08 02:47:03,017 - INFO - Round(30/30)
2024-06-08 02:47:13,958 - INFO - >>training completed		| train loss=0.0007023252621619342, val loss=0.0006555799567837097
2024-06-08 02:47:13,958 - INFO - #目前最低損失: train=0.00032619275950129773, val=0.00031832466829431896
2024-06-08 02:47:13,959 - INFO - #目前最佳隱藏層神經元數量: train=5, val=4
2024-06-08 02:47:13,959 - INFO - #目前最佳參數:
-train:
W1=[[-0.27910273 -0.07693657]
 [ 0.35219258  1.28642646]
 [-0.38264138  0.09561274]
 [-0.0580835  -0.44376467]
 [-0.13316277 -0.3223864 ]]
b1=[[ 0.00486994]
 [-0.00252325]
 [-0.00546364]
 [ 0.00742982]
 [-0.00596721]]
W2=[[-1.60579737 -0.1815528  -0.37274861 -1.08241148 -1.07133284]]
b2=[[0.0021013]]
-val:
W1=[[-0.29088747 -0.01954112]
 [ 0.22078031  0.09249363]
 [-0.13536749 -0.17865703]
 [-0.02956763 -0.28102486]]
b1=[[ 0.00203831]
 [-0.00320682]
 [-0.00170268]
 [ 0.00145274]]
W2=[[-1.18782761  0.96809854 -0.9828277  -1.60472439]]
b2=[[0.00265259]]

2024-06-08 02:47:13,960 - INFO - ----Hidden_size 6:
2024-06-08 02:47:13,960 - INFO - Round(1/30)
2024-06-08 02:47:24,555 - INFO - >>training completed		| train loss=0.0002871659588335, val loss=0.0002801595643937931
2024-06-08 02:47:24,556 - INFO - Model saved to best_val_model.npz
2024-06-08 02:47:24,557 - INFO - Model saved to best_train_model.npz
2024-06-08 02:47:24,557 - INFO - Round(2/30)
2024-06-08 02:47:35,156 - INFO - >>training completed		| train loss=0.0008808175279066121, val loss=0.0008404641570634163
2024-06-08 02:47:35,156 - INFO - Round(3/30)
2024-06-08 02:47:45,572 - INFO - >>training completed		| train loss=0.0009316858909055016, val loss=0.0008633042211515209
2024-06-08 02:47:45,572 - INFO - Round(4/30)
2024-06-08 02:47:56,056 - INFO - >>training completed		| train loss=0.0005357905875485178, val loss=0.0005005401769386969
2024-06-08 02:47:56,056 - INFO - Round(5/30)
2024-06-08 02:48:07,139 - INFO - >>training completed		| train loss=0.00045795252352432434, val loss=0.00042949609166624856
2024-06-08 02:48:07,140 - INFO - Round(6/30)
2024-06-08 02:48:19,092 - INFO - >>training completed		| train loss=0.00018815851562480843, val loss=0.00018417275375567755
2024-06-08 02:48:19,093 - INFO - Model saved to best_val_model.npz
2024-06-08 02:48:19,093 - INFO - Model saved to best_train_model.npz
2024-06-08 02:48:19,093 - INFO - Round(7/30)
2024-06-08 02:48:29,939 - INFO - >>training completed		| train loss=0.00030846060720266763, val loss=0.0002880030052781201
2024-06-08 02:48:29,939 - INFO - Round(8/30)
2024-06-08 02:48:40,755 - INFO - >>training completed		| train loss=0.000489794516982561, val loss=0.00045809496669643767
2024-06-08 02:48:40,755 - INFO - Round(9/30)
2024-06-08 02:48:51,627 - INFO - >>training completed		| train loss=0.000936394040955222, val loss=0.0008760716908163418
2024-06-08 02:48:51,627 - INFO - Round(10/30)
2024-06-08 02:49:02,648 - INFO - >>training completed		| train loss=0.000446653525536196, val loss=0.00041586884168920733
2024-06-08 02:49:02,648 - INFO - Round(11/30)
2024-06-08 02:49:13,455 - INFO - >>training completed		| train loss=0.0005355785528218641, val loss=0.0005030657353581814
2024-06-08 02:49:13,455 - INFO - Round(12/30)
2024-06-08 02:49:24,486 - INFO - >>training completed		| train loss=0.0003280142638215379, val loss=0.00031883916568513593
2024-06-08 02:49:24,486 - INFO - Round(13/30)
2024-06-08 02:49:35,398 - INFO - >>training completed		| train loss=0.0005291422836605475, val loss=0.0005008717670547645
2024-06-08 02:49:35,398 - INFO - Round(14/30)
2024-06-08 02:49:46,117 - INFO - >>training completed		| train loss=0.00038363768774429954, val loss=0.0003585352218462788
2024-06-08 02:49:46,117 - INFO - Round(15/30)
2024-06-08 02:49:56,826 - INFO - >>training completed		| train loss=0.0002955557102299347, val loss=0.0002846243604004358
2024-06-08 02:49:56,827 - INFO - Round(16/30)
2024-06-08 02:50:07,476 - INFO - >>training completed		| train loss=0.0005154801805724642, val loss=0.000484778851228766
2024-06-08 02:50:07,476 - INFO - Round(17/30)
2024-06-08 02:50:18,854 - INFO - >>training completed		| train loss=0.0006159533373171318, val loss=0.0005781048827206784
2024-06-08 02:50:18,854 - INFO - Round(18/30)
2024-06-08 02:50:29,941 - INFO - >>training completed		| train loss=0.0005347012526941078, val loss=0.0004997117618440795
2024-06-08 02:50:29,941 - INFO - Round(19/30)
2024-06-08 02:50:40,747 - INFO - >>training completed		| train loss=0.00021438995191033915, val loss=0.00020732462123463152
2024-06-08 02:50:40,747 - INFO - Round(20/30)
2024-06-08 02:50:51,480 - INFO - >>training completed		| train loss=0.0006132013517359444, val loss=0.0005698914395086994
2024-06-08 02:50:51,480 - INFO - Round(21/30)
2024-06-08 02:51:02,256 - INFO - >>training completed		| train loss=0.0004600966646341287, val loss=0.0004447986291387218
2024-06-08 02:51:02,256 - INFO - Round(22/30)
2024-06-08 02:51:13,031 - INFO - >>training completed		| train loss=0.0007610303426068691, val loss=0.0007125868026417319
2024-06-08 02:51:13,031 - INFO - Round(23/30)
2024-06-08 02:51:24,032 - INFO - >>training completed		| train loss=0.0005461825274116226, val loss=0.0005113012883574551
2024-06-08 02:51:24,032 - INFO - Round(24/30)
2024-06-08 02:51:35,256 - INFO - >>training completed		| train loss=0.0005479938113424959, val loss=0.0005145519153165714
2024-06-08 02:51:35,256 - INFO - Round(25/30)
2024-06-08 02:51:45,926 - INFO - >>training completed		| train loss=0.0002830870033870594, val loss=0.00027499407856442605
2024-06-08 02:51:45,926 - INFO - Round(26/30)
2024-06-08 02:51:56,651 - INFO - >>training completed		| train loss=0.0005733558131464946, val loss=0.000539575688153436
2024-06-08 02:51:56,651 - INFO - Round(27/30)
2024-06-08 02:52:07,299 - INFO - >>training completed		| train loss=0.00046681653280235453, val loss=0.00045994626191573517
2024-06-08 02:52:07,299 - INFO - Round(28/30)
2024-06-08 02:52:17,795 - INFO - >>training completed		| train loss=0.0004096500869567487, val loss=0.00038310961486202975
2024-06-08 02:52:17,795 - INFO - Round(29/30)
2024-06-08 02:52:28,579 - INFO - >>training completed		| train loss=0.0014985776324623968, val loss=0.0014517577889035782
2024-06-08 02:52:28,579 - INFO - Round(30/30)
2024-06-08 02:52:39,191 - INFO - >>training completed		| train loss=0.0004435252109587709, val loss=0.0004182112699172534
2024-06-08 02:52:39,191 - INFO - #目前最低損失: train=0.00018815851562480843, val=0.00018417275375567755
2024-06-08 02:52:39,192 - INFO - #目前最佳隱藏層神經元數量: train=6, val=6
2024-06-08 02:52:39,193 - INFO - #目前最佳參數:
-train:
W1=[[-0.13659356  0.37328887]
 [ 0.13188479  0.22382266]
 [ 0.28210077  0.13785978]
 [ 0.1855403   0.19446429]
 [-0.94619231 -0.33693264]
 [-0.4543031  -0.01493423]]
b1=[[ 0.00414786]
 [-0.00905049]
 [ 0.00228551]
 [ 0.00406991]
 [ 0.00065674]
 [ 0.00307211]]
W2=[[ 0.53367713  0.93042228  1.25992048  1.10195464  0.23979856 -0.6795733 ]]
b2=[[0.00215662]]
-val:
W1=[[-0.13659356  0.37328887]
 [ 0.13188479  0.22382266]
 [ 0.28210077  0.13785978]
 [ 0.1855403   0.19446429]
 [-0.94619231 -0.33693264]
 [-0.4543031  -0.01493423]]
b1=[[ 0.00414786]
 [-0.00905049]
 [ 0.00228551]
 [ 0.00406991]
 [ 0.00065674]
 [ 0.00307211]]
W2=[[ 0.53367713  0.93042228  1.25992048  1.10195464  0.23979856 -0.6795733 ]]
b2=[[0.00215662]]

2024-06-08 02:52:39,193 - INFO - ----Hidden_size 7:
2024-06-08 02:52:39,194 - INFO - Round(1/30)
2024-06-08 02:52:49,964 - INFO - >>training completed		| train loss=0.00039774971288724753, val loss=0.0003739563006683844
2024-06-08 02:52:49,964 - INFO - Round(2/30)
2024-06-08 02:53:01,038 - INFO - >>training completed		| train loss=0.00020393752410401538, val loss=0.00019633524399206948
2024-06-08 02:53:01,038 - INFO - Round(3/30)
2024-06-08 02:53:11,647 - INFO - >>training completed		| train loss=0.0003019887063930065, val loss=0.00028675269822732837
2024-06-08 02:53:11,647 - INFO - Round(4/30)
2024-06-08 02:53:22,328 - INFO - >>training completed		| train loss=0.0007687927086520679, val loss=0.0007705917205433796
2024-06-08 02:53:22,328 - INFO - Round(5/30)
2024-06-08 02:53:32,783 - INFO - >>training completed		| train loss=0.0005602938493435418, val loss=0.0005265564048156139
2024-06-08 02:53:32,783 - INFO - Round(6/30)
2024-06-08 02:53:43,916 - INFO - >>training completed		| train loss=0.0004068239196425927, val loss=0.00038187563294382463
2024-06-08 02:53:43,916 - INFO - Round(7/30)
2024-06-08 02:53:54,999 - INFO - >>training completed		| train loss=0.00027500139134864287, val loss=0.0002674622727704829
2024-06-08 02:53:54,999 - INFO - Round(8/30)
2024-06-08 02:54:06,152 - INFO - >>training completed		| train loss=0.00037135784507364404, val loss=0.0003685448806598716
2024-06-08 02:54:06,152 - INFO - Round(9/30)
2024-06-08 02:54:17,409 - INFO - >>training completed		| train loss=0.0003727059190028652, val loss=0.00035844608776397724
2024-06-08 02:54:17,409 - INFO - Round(10/30)
2024-06-08 02:54:28,334 - INFO - >>training completed		| train loss=0.0005194088242381316, val loss=0.000521265949794657
2024-06-08 02:54:28,334 - INFO - Round(11/30)
2024-06-08 02:54:39,080 - INFO - >>training completed		| train loss=0.00031276706606797795, val loss=0.00031365292123776417
2024-06-08 02:54:39,080 - INFO - Round(12/30)
2024-06-08 02:54:49,834 - INFO - >>training completed		| train loss=0.0002530942750370767, val loss=0.0002459356329602612
2024-06-08 02:54:49,834 - INFO - Round(13/30)
2024-06-08 02:55:00,712 - INFO - >>training completed		| train loss=0.0001935565952974875, val loss=0.00019088369622600787
2024-06-08 02:55:00,712 - INFO - Round(14/30)
2024-06-08 02:55:11,301 - INFO - >>training completed		| train loss=0.0005719050563270665, val loss=0.0005378855107271397
2024-06-08 02:55:11,301 - INFO - Round(15/30)
2024-06-08 02:55:21,851 - INFO - >>training completed		| train loss=0.00022051708523429718, val loss=0.0002079949864746624
2024-06-08 02:55:21,851 - INFO - Round(16/30)
2024-06-08 02:55:32,245 - INFO - >>training completed		| train loss=0.0002321895528056312, val loss=0.0002280674675550829
2024-06-08 02:55:32,246 - INFO - Round(17/30)
2024-06-08 02:55:42,675 - INFO - >>training completed		| train loss=0.0005286828727466014, val loss=0.0004943857081719845
2024-06-08 02:55:42,676 - INFO - Round(18/30)
2024-06-08 02:55:53,152 - INFO - >>training completed		| train loss=0.00033647247427193665, val loss=0.0003303042568681525
2024-06-08 02:55:53,152 - INFO - Round(19/30)
2024-06-08 02:56:03,678 - INFO - >>training completed		| train loss=0.0004919897533652697, val loss=0.00047432012042658545
2024-06-08 02:56:03,678 - INFO - Round(20/30)
2024-06-08 02:56:14,880 - INFO - >>training completed		| train loss=0.0005105773863468447, val loss=0.00048708539382460775
2024-06-08 02:56:14,880 - INFO - Round(21/30)
2024-06-08 02:56:26,537 - INFO - >>training completed		| train loss=0.0005057587804820897, val loss=0.0004936803520515016
2024-06-08 02:56:26,537 - INFO - Round(22/30)
2024-06-08 02:56:38,271 - INFO - >>training completed		| train loss=0.0006747122666313712, val loss=0.0006334395837113972
2024-06-08 02:56:38,271 - INFO - Round(23/30)
2024-06-08 02:56:48,979 - INFO - >>training completed		| train loss=0.00023372830314955076, val loss=0.00022640892558916688
2024-06-08 02:56:48,979 - INFO - Round(24/30)
2024-06-08 02:56:59,625 - INFO - >>training completed		| train loss=0.0004744926274487112, val loss=0.0004489848457594131
2024-06-08 02:56:59,625 - INFO - Round(25/30)
2024-06-08 02:57:10,545 - INFO - >>training completed		| train loss=0.0004697549000300613, val loss=0.00044512027005205236
2024-06-08 02:57:10,545 - INFO - Round(26/30)
2024-06-08 02:57:21,395 - INFO - >>training completed		| train loss=0.00044678547336838334, val loss=0.00042099454112457126
2024-06-08 02:57:21,395 - INFO - Round(27/30)
2024-06-08 02:57:32,805 - INFO - >>training completed		| train loss=0.00038701001705369675, val loss=0.0003655624829671435
2024-06-08 02:57:32,805 - INFO - Round(28/30)
2024-06-08 02:57:43,449 - INFO - >>training completed		| train loss=0.0009243587016945807, val loss=0.0008872171421278928
2024-06-08 02:57:43,449 - INFO - Round(29/30)
2024-06-08 02:57:53,920 - INFO - >>training completed		| train loss=0.0003298610789460141, val loss=0.0003215518945224174
2024-06-08 02:57:53,920 - INFO - Round(30/30)
2024-06-08 02:58:04,297 - INFO - >>training completed		| train loss=0.0011013655391355042, val loss=0.0010423281836116937
2024-06-08 02:58:04,297 - INFO - #目前最低損失: train=0.00018815851562480843, val=0.00018417275375567755
2024-06-08 02:58:04,297 - INFO - #目前最佳隱藏層神經元數量: train=6, val=6
2024-06-08 02:58:04,299 - INFO - #目前最佳參數:
-train:
W1=[[-0.13659356  0.37328887]
 [ 0.13188479  0.22382266]
 [ 0.28210077  0.13785978]
 [ 0.1855403   0.19446429]
 [-0.94619231 -0.33693264]
 [-0.4543031  -0.01493423]]
b1=[[ 0.00414786]
 [-0.00905049]
 [ 0.00228551]
 [ 0.00406991]
 [ 0.00065674]
 [ 0.00307211]]
W2=[[ 0.53367713  0.93042228  1.25992048  1.10195464  0.23979856 -0.6795733 ]]
b2=[[0.00215662]]
-val:
W1=[[-0.13659356  0.37328887]
 [ 0.13188479  0.22382266]
 [ 0.28210077  0.13785978]
 [ 0.1855403   0.19446429]
 [-0.94619231 -0.33693264]
 [-0.4543031  -0.01493423]]
b1=[[ 0.00414786]
 [-0.00905049]
 [ 0.00228551]
 [ 0.00406991]
 [ 0.00065674]
 [ 0.00307211]]
W2=[[ 0.53367713  0.93042228  1.25992048  1.10195464  0.23979856 -0.6795733 ]]
b2=[[0.00215662]]

2024-06-08 02:58:04,300 - INFO - ----Hidden_size 8:
2024-06-08 02:58:04,300 - INFO - Round(1/30)
2024-06-08 02:58:15,045 - INFO - >>training completed		| train loss=0.0005058803465059372, val loss=0.0004810055038871138
2024-06-08 02:58:15,045 - INFO - Round(2/30)
2024-06-08 02:58:25,538 - INFO - >>training completed		| train loss=0.0002327831759938883, val loss=0.0002283142827295343
2024-06-08 02:58:25,538 - INFO - Round(3/30)
2024-06-08 02:58:36,073 - INFO - >>training completed		| train loss=0.00018929109211038026, val loss=0.00018635718495061616
2024-06-08 02:58:36,073 - INFO - Round(4/30)
2024-06-08 02:58:46,780 - INFO - >>training completed		| train loss=0.00030247433478339844, val loss=0.00030553255488127847
2024-06-08 02:58:46,780 - INFO - Round(5/30)
2024-06-08 02:58:57,451 - INFO - >>training completed		| train loss=0.0007089353400802776, val loss=0.0006761708705072849
2024-06-08 02:58:57,451 - INFO - Round(6/30)
2024-06-08 02:59:08,387 - INFO - >>training completed		| train loss=0.00019869972267290122, val loss=0.00019636501544390917
2024-06-08 02:59:08,387 - INFO - Round(7/30)
2024-06-08 02:59:18,828 - INFO - >>training completed		| train loss=0.0002922797273747956, val loss=0.0002784707447600965
2024-06-08 02:59:18,829 - INFO - Round(8/30)
2024-06-08 02:59:29,420 - INFO - >>training completed		| train loss=0.00042624703692418126, val loss=0.0004014623705662891
2024-06-08 02:59:29,420 - INFO - Round(9/30)
2024-06-08 02:59:40,494 - INFO - >>training completed		| train loss=0.0003080541206107874, val loss=0.0003033889545625235
2024-06-08 02:59:40,494 - INFO - Round(10/30)
2024-06-08 02:59:51,443 - INFO - >>training completed		| train loss=0.00019765051744344568, val loss=0.0001968287880138064
2024-06-08 02:59:51,443 - INFO - Round(11/30)
2024-06-08 03:00:02,570 - INFO - >>training completed		| train loss=0.00046838704603605454, val loss=0.00046548105471344055
2024-06-08 03:00:02,570 - INFO - Round(12/30)
2024-06-08 03:00:13,433 - INFO - >>training completed		| train loss=0.000350000005415475, val loss=0.0003468323332741993
2024-06-08 03:00:13,433 - INFO - Round(13/30)
2024-06-08 03:00:24,209 - INFO - >>training completed		| train loss=0.00031659937785843663, val loss=0.0003146623381217656
2024-06-08 03:00:24,209 - INFO - Round(14/30)
2024-06-08 03:00:35,034 - INFO - >>training completed		| train loss=0.0004945603091623577, val loss=0.0004691253755251492
2024-06-08 03:00:35,035 - INFO - Round(15/30)
2024-06-08 03:00:45,924 - INFO - >>training completed		| train loss=0.0007117945678289596, val loss=0.000677400529154949
2024-06-08 03:00:45,924 - INFO - Round(16/30)
2024-06-08 03:00:56,811 - INFO - >>training completed		| train loss=0.00024715635907303514, val loss=0.00024179631121239837
2024-06-08 03:00:56,811 - INFO - Round(17/30)
2024-06-08 03:01:07,599 - INFO - >>training completed		| train loss=0.000461477624031251, val loss=0.0004370414831524459
2024-06-08 03:01:07,600 - INFO - Round(18/30)
2024-06-08 03:01:18,117 - INFO - >>training completed		| train loss=0.0002878798646898071, val loss=0.00027519282137164225
2024-06-08 03:01:18,117 - INFO - Round(19/30)
2024-06-08 03:01:28,684 - INFO - >>training completed		| train loss=0.0006571316481485832, val loss=0.0006293103286212547
2024-06-08 03:01:28,684 - INFO - Round(20/30)
2024-06-08 03:01:39,307 - INFO - >>training completed		| train loss=0.0002468102489076665, val loss=0.00024700716761612984
2024-06-08 03:01:39,308 - INFO - Round(21/30)
2024-06-08 03:01:49,914 - INFO - >>training completed		| train loss=0.0004970148258281934, val loss=0.0004969968687904667
2024-06-08 03:01:49,914 - INFO - Round(22/30)
2024-06-08 03:02:00,607 - INFO - >>training completed		| train loss=0.0002472173209848327, val loss=0.00023299722468506678
2024-06-08 03:02:00,607 - INFO - Round(23/30)
2024-06-08 03:02:11,469 - INFO - >>training completed		| train loss=0.00024991426637366695, val loss=0.0002512948752141415
2024-06-08 03:02:11,469 - INFO - Round(24/30)
2024-06-08 03:02:23,125 - INFO - >>training completed		| train loss=0.00047569328352631117, val loss=0.00045360914339355056
2024-06-08 03:02:23,125 - INFO - Round(25/30)
2024-06-08 03:02:34,748 - INFO - >>training completed		| train loss=0.0005303317073385443, val loss=0.0005151037226254591
2024-06-08 03:02:34,748 - INFO - Round(26/30)
2024-06-08 03:02:45,633 - INFO - >>training completed		| train loss=0.0004914724323758482, val loss=0.000469069964266159
2024-06-08 03:02:45,633 - INFO - Round(27/30)
2024-06-08 03:02:56,269 - INFO - >>training completed		| train loss=0.0005889051414265093, val loss=0.0005679393389397734
2024-06-08 03:02:56,269 - INFO - Round(28/30)
2024-06-08 03:03:07,042 - INFO - >>training completed		| train loss=0.0002245484309618763, val loss=0.00022165439300315433
2024-06-08 03:03:07,042 - INFO - Round(29/30)
2024-06-08 03:03:17,784 - INFO - >>training completed		| train loss=0.0006242824724905625, val loss=0.0005941456184327932
2024-06-08 03:03:17,784 - INFO - Round(30/30)
2024-06-08 03:03:28,680 - INFO - >>training completed		| train loss=0.0004327408103026715, val loss=0.0004129527997046355
2024-06-08 03:03:28,680 - INFO - #目前最低損失: train=0.00018815851562480843, val=0.00018417275375567755
2024-06-08 03:03:28,680 - INFO - #目前最佳隱藏層神經元數量: train=6, val=6
2024-06-08 03:03:28,681 - INFO - #目前最佳參數:
-train:
W1=[[-0.13659356  0.37328887]
 [ 0.13188479  0.22382266]
 [ 0.28210077  0.13785978]
 [ 0.1855403   0.19446429]
 [-0.94619231 -0.33693264]
 [-0.4543031  -0.01493423]]
b1=[[ 0.00414786]
 [-0.00905049]
 [ 0.00228551]
 [ 0.00406991]
 [ 0.00065674]
 [ 0.00307211]]
W2=[[ 0.53367713  0.93042228  1.25992048  1.10195464  0.23979856 -0.6795733 ]]
b2=[[0.00215662]]
-val:
W1=[[-0.13659356  0.37328887]
 [ 0.13188479  0.22382266]
 [ 0.28210077  0.13785978]
 [ 0.1855403   0.19446429]
 [-0.94619231 -0.33693264]
 [-0.4543031  -0.01493423]]
b1=[[ 0.00414786]
 [-0.00905049]
 [ 0.00228551]
 [ 0.00406991]
 [ 0.00065674]
 [ 0.00307211]]
W2=[[ 0.53367713  0.93042228  1.25992048  1.10195464  0.23979856 -0.6795733 ]]
b2=[[0.00215662]]

2024-06-08 03:03:28,682 - INFO - ----Hidden_size 9:
2024-06-08 03:03:28,682 - INFO - Round(1/30)
2024-06-08 03:03:40,100 - INFO - >>training completed		| train loss=0.00010858449210704628, val loss=0.0001089044171459664
2024-06-08 03:03:40,100 - INFO - Model saved to best_val_model.npz
2024-06-08 03:03:40,101 - INFO - Model saved to best_train_model.npz
2024-06-08 03:03:40,102 - INFO - Round(2/30)
2024-06-08 03:03:51,497 - INFO - >>training completed		| train loss=0.00048641593280899256, val loss=0.0004660915269795034
2024-06-08 03:03:51,497 - INFO - Round(3/30)
2024-06-08 03:04:02,569 - INFO - >>training completed		| train loss=0.00026187340480909524, val loss=0.0002566602224527632
2024-06-08 03:04:02,569 - INFO - Round(4/30)
2024-06-08 03:04:13,828 - INFO - >>training completed		| train loss=0.00030390231856650173, val loss=0.0002949857749724382
2024-06-08 03:04:13,828 - INFO - Round(5/30)
2024-06-08 03:04:24,373 - INFO - >>training completed		| train loss=0.00024143304022610325, val loss=0.00022961049742156213
2024-06-08 03:04:24,373 - INFO - Round(6/30)
2024-06-08 03:04:35,378 - INFO - >>training completed		| train loss=0.00034843835071253645, val loss=0.00034595979349138253
2024-06-08 03:04:35,378 - INFO - Round(7/30)
2024-06-08 03:04:45,724 - INFO - >>training completed		| train loss=0.00031455530846889046, val loss=0.00031384336912280243
2024-06-08 03:04:45,724 - INFO - Round(8/30)
2024-06-08 03:04:56,118 - INFO - >>training completed		| train loss=0.00037960966459905715, val loss=0.00036080563707264275
2024-06-08 03:04:56,118 - INFO - Round(9/30)
2024-06-08 03:05:06,580 - INFO - >>training completed		| train loss=0.0005084588670879176, val loss=0.0004830095686934289
2024-06-08 03:05:06,580 - INFO - Round(10/30)
2024-06-08 03:05:17,358 - INFO - >>training completed		| train loss=0.00016867600063848648, val loss=0.0001638953154313494
2024-06-08 03:05:17,358 - INFO - Round(11/30)
2024-06-08 03:05:27,928 - INFO - >>training completed		| train loss=0.0002572436031078546, val loss=0.0002583650615441531
2024-06-08 03:05:27,928 - INFO - Round(12/30)
2024-06-08 03:05:38,597 - INFO - >>training completed		| train loss=0.0002845606920909718, val loss=0.00026853385620805145
2024-06-08 03:05:38,597 - INFO - Round(13/30)
2024-06-08 03:05:49,281 - INFO - >>training completed		| train loss=0.00047390555541814496, val loss=0.00044773472998190905
2024-06-08 03:05:49,281 - INFO - Round(14/30)
2024-06-08 03:05:59,890 - INFO - >>training completed		| train loss=0.00040377343878423, val loss=0.0003836573712085982
2024-06-08 03:05:59,890 - INFO - Round(15/30)
2024-06-08 03:06:10,482 - INFO - >>training completed		| train loss=0.00027619138362682525, val loss=0.0002769686792597845
2024-06-08 03:06:10,482 - INFO - Round(16/30)
2024-06-08 03:06:21,167 - INFO - >>training completed		| train loss=0.0003660154560077967, val loss=0.0003475553308024498
2024-06-08 03:06:21,168 - INFO - Round(17/30)
2024-06-08 03:06:31,752 - INFO - >>training completed		| train loss=9.54265301468961e-05, val loss=9.532012328877713e-05
2024-06-08 03:06:31,753 - INFO - Model saved to best_val_model.npz
2024-06-08 03:06:31,753 - INFO - Model saved to best_train_model.npz
2024-06-08 03:06:31,753 - INFO - Round(18/30)
2024-06-08 03:06:42,404 - INFO - >>training completed		| train loss=0.000314484528187974, val loss=0.00029553291857579387
2024-06-08 03:06:42,404 - INFO - Round(19/30)
2024-06-08 03:06:53,054 - INFO - >>training completed		| train loss=0.0002767114150107142, val loss=0.00026819993333728934
2024-06-08 03:06:53,055 - INFO - Round(20/30)
2024-06-08 03:07:03,930 - INFO - >>training completed		| train loss=0.00019637977264562359, val loss=0.0001885787099111961
2024-06-08 03:07:03,930 - INFO - Round(21/30)
2024-06-08 03:07:14,698 - INFO - >>training completed		| train loss=0.0008283174559467377, val loss=0.0007874555910703582
2024-06-08 03:07:14,698 - INFO - Round(22/30)
2024-06-08 03:07:25,439 - INFO - >>training completed		| train loss=0.0003790584322155797, val loss=0.00035495202856917406
2024-06-08 03:07:25,439 - INFO - Round(23/30)
2024-06-08 03:07:35,990 - INFO - >>training completed		| train loss=0.0002905750881104401, val loss=0.00027348756035010523
2024-06-08 03:07:35,990 - INFO - Round(24/30)
2024-06-08 03:07:47,407 - INFO - >>training completed		| train loss=0.00011560868577978748, val loss=0.0001130531311683115
2024-06-08 03:07:47,407 - INFO - Round(25/30)
2024-06-08 03:07:58,739 - INFO - >>training completed		| train loss=0.00045772936868652573, val loss=0.0004338486663287829
2024-06-08 03:07:58,739 - INFO - Round(26/30)
2024-06-08 03:08:10,001 - INFO - >>training completed		| train loss=0.00020100616640363723, val loss=0.00019627555050540042
2024-06-08 03:08:10,001 - INFO - Round(27/30)
2024-06-08 03:08:21,327 - INFO - >>training completed		| train loss=0.00029399775436590335, val loss=0.0002903689252958785
2024-06-08 03:08:21,327 - INFO - Round(28/30)
2024-06-08 03:08:32,545 - INFO - >>training completed		| train loss=0.0002781012365556547, val loss=0.00027291957920406426
2024-06-08 03:08:32,545 - INFO - Round(29/30)
2024-06-08 03:08:43,405 - INFO - >>training completed		| train loss=0.00036109898734189386, val loss=0.0003390319917187169
2024-06-08 03:08:43,405 - INFO - Round(30/30)
2024-06-08 03:08:54,492 - INFO - >>training completed		| train loss=0.0002766668405511695, val loss=0.0002688735574315462
2024-06-08 03:08:54,492 - INFO - #目前最低損失: train=9.54265301468961e-05, val=9.532012328877713e-05
2024-06-08 03:08:54,492 - INFO - #目前最佳隱藏層神經元數量: train=9, val=9
2024-06-08 03:08:54,493 - INFO - #目前最佳參數:
-train:
W1=[[-0.24003021 -0.2083404 ]
 [ 1.27093773  0.04147215]
 [ 0.19454277  0.24000448]
 [ 0.62374422 -0.22278188]
 [ 0.21630571  0.21675307]
 [ 0.07660006  0.3208313 ]
 [ 0.80044974 -0.8469555 ]
 [-0.5188491  -0.9939299 ]
 [ 0.11555097  0.2990386 ]]
b1=[[ 0.00196161]
 [-0.00495221]
 [-0.000104  ]
 [-0.00249698]
 [-0.00052502]
 [-0.00504953]
 [-0.00458132]
 [ 0.00055554]
 [ 0.00700574]]
W2=[[-0.75073753 -0.14044602  1.41366374  0.52357817  0.78671398  0.56924779
  -0.09727499  0.18355285  0.23524491]]
b2=[[0.00213001]]
-val:
W1=[[-0.24003021 -0.2083404 ]
 [ 1.27093773  0.04147215]
 [ 0.19454277  0.24000448]
 [ 0.62374422 -0.22278188]
 [ 0.21630571  0.21675307]
 [ 0.07660006  0.3208313 ]
 [ 0.80044974 -0.8469555 ]
 [-0.5188491  -0.9939299 ]
 [ 0.11555097  0.2990386 ]]
b1=[[ 0.00196161]
 [-0.00495221]
 [-0.000104  ]
 [-0.00249698]
 [-0.00052502]
 [-0.00504953]
 [-0.00458132]
 [ 0.00055554]
 [ 0.00700574]]
W2=[[-0.75073753 -0.14044602  1.41366374  0.52357817  0.78671398  0.56924779
  -0.09727499  0.18355285  0.23524491]]
b2=[[0.00213001]]

2024-06-08 03:08:54,494 - INFO - ----Hidden_size 10:
2024-06-08 03:08:54,494 - INFO - Round(1/30)
2024-06-08 03:09:05,339 - INFO - >>training completed		| train loss=0.0001330515948878151, val loss=0.0001273049825218875
2024-06-08 03:09:05,339 - INFO - Round(2/30)
2024-06-08 03:09:16,659 - INFO - >>training completed		| train loss=0.0002190429049555459, val loss=0.00021897616740221938
2024-06-08 03:09:16,659 - INFO - Round(3/30)
2024-06-08 03:09:28,051 - INFO - >>training completed		| train loss=0.0003180259198557188, val loss=0.00029931469796284286
2024-06-08 03:09:28,051 - INFO - Round(4/30)
2024-06-08 03:09:39,505 - INFO - >>training completed		| train loss=0.000375836967251738, val loss=0.0003575566093574288
2024-06-08 03:09:39,506 - INFO - Round(5/30)
2024-06-08 03:09:50,762 - INFO - >>training completed		| train loss=0.00017605865698044613, val loss=0.00017522999708486164
2024-06-08 03:09:50,762 - INFO - Round(6/30)
2024-06-08 03:10:01,881 - INFO - >>training completed		| train loss=0.0004454182807334875, val loss=0.00044102354307843473
2024-06-08 03:10:01,881 - INFO - Round(7/30)
2024-06-08 03:10:13,182 - INFO - >>training completed		| train loss=0.00035181877335216, val loss=0.0003365366552443983
2024-06-08 03:10:13,182 - INFO - Round(8/30)
2024-06-08 03:10:24,522 - INFO - >>training completed		| train loss=0.00014712572340486575, val loss=0.0001435300138883653
2024-06-08 03:10:24,523 - INFO - Round(9/30)
2024-06-08 03:10:35,999 - INFO - >>training completed		| train loss=0.00013785536105212842, val loss=0.00013525137859013079
2024-06-08 03:10:35,999 - INFO - Round(10/30)
2024-06-08 03:10:47,294 - INFO - >>training completed		| train loss=0.00011139892540465225, val loss=0.00011161389767440865
2024-06-08 03:10:47,294 - INFO - Round(11/30)
2024-06-08 03:10:58,605 - INFO - >>training completed		| train loss=0.00026316394328936243, val loss=0.00026072900675807225
2024-06-08 03:10:58,605 - INFO - Round(12/30)
2024-06-08 03:11:09,885 - INFO - >>training completed		| train loss=0.00036636898623741416, val loss=0.0003448656552593323
2024-06-08 03:11:09,885 - INFO - Round(13/30)
2024-06-08 03:11:21,195 - INFO - >>training completed		| train loss=0.0003838025695069567, val loss=0.0003801729771401393
2024-06-08 03:11:21,195 - INFO - Round(14/30)
2024-06-08 03:11:32,667 - INFO - >>training completed		| train loss=0.00042591431901687217, val loss=0.00040539845134217035
2024-06-08 03:11:32,667 - INFO - Round(15/30)
2024-06-08 03:11:44,224 - INFO - >>training completed		| train loss=0.0006864662276494953, val loss=0.0006533298062237563
2024-06-08 03:11:44,224 - INFO - Round(16/30)
2024-06-08 03:11:55,652 - INFO - >>training completed		| train loss=0.0003580959320664115, val loss=0.000339409303508711
2024-06-08 03:11:55,652 - INFO - Round(17/30)
2024-06-08 03:12:06,986 - INFO - >>training completed		| train loss=0.00025804470103206836, val loss=0.00024163313700624453
2024-06-08 03:12:06,986 - INFO - Round(18/30)
2024-06-08 03:12:18,666 - INFO - >>training completed		| train loss=0.0005083497965396273, val loss=0.00048503642629737446
2024-06-08 03:12:18,666 - INFO - Round(19/30)
2024-06-08 03:12:30,375 - INFO - >>training completed		| train loss=0.00022971037832294453, val loss=0.00023043596185296034
2024-06-08 03:12:30,375 - INFO - Round(20/30)
2024-06-08 03:12:41,657 - INFO - >>training completed		| train loss=0.0003389020454634567, val loss=0.00033781452951936827
2024-06-08 03:12:41,657 - INFO - Round(21/30)
2024-06-08 03:12:53,458 - INFO - >>training completed		| train loss=0.00021475657102636283, val loss=0.00020514021626323237
2024-06-08 03:12:53,458 - INFO - Round(22/30)
2024-06-08 03:13:05,100 - INFO - >>training completed		| train loss=0.0004865535412593708, val loss=0.0004577199533290884
2024-06-08 03:13:05,100 - INFO - Round(23/30)
2024-06-08 03:13:16,524 - INFO - >>training completed		| train loss=0.00037186578105104543, val loss=0.00036838760748213916
2024-06-08 03:13:16,524 - INFO - Round(24/30)
2024-06-08 03:13:27,877 - INFO - >>training completed		| train loss=0.00024441858358463823, val loss=0.00024227963269070766
2024-06-08 03:13:27,877 - INFO - Round(25/30)
2024-06-08 03:13:39,238 - INFO - >>training completed		| train loss=0.0002382547278392776, val loss=0.00023852919062811273
2024-06-08 03:13:39,238 - INFO - Round(26/30)
2024-06-08 03:13:50,590 - INFO - >>training completed		| train loss=0.0003005887301533789, val loss=0.0002909451872790381
2024-06-08 03:13:50,590 - INFO - Round(27/30)
2024-06-08 03:14:01,896 - INFO - >>training completed		| train loss=0.00013874433864338132, val loss=0.00013768262072228694
2024-06-08 03:14:01,897 - INFO - Round(28/30)
2024-06-08 03:14:13,427 - INFO - >>training completed		| train loss=0.00035789161528163726, val loss=0.0003377140050449069
2024-06-08 03:14:13,427 - INFO - Round(29/30)
2024-06-08 03:14:25,119 - INFO - >>training completed		| train loss=0.00016196743685290566, val loss=0.00015848049985200485
2024-06-08 03:14:25,119 - INFO - Round(30/30)
2024-06-08 03:14:36,965 - INFO - >>training completed		| train loss=0.00034016638468663127, val loss=0.0003436247750257923
2024-06-08 03:14:36,965 - INFO - #目前最低損失: train=9.54265301468961e-05, val=9.532012328877713e-05
2024-06-08 03:14:36,965 - INFO - #目前最佳隱藏層神經元數量: train=9, val=9
2024-06-08 03:14:36,967 - INFO - #目前最佳參數:
-train:
W1=[[-0.24003021 -0.2083404 ]
 [ 1.27093773  0.04147215]
 [ 0.19454277  0.24000448]
 [ 0.62374422 -0.22278188]
 [ 0.21630571  0.21675307]
 [ 0.07660006  0.3208313 ]
 [ 0.80044974 -0.8469555 ]
 [-0.5188491  -0.9939299 ]
 [ 0.11555097  0.2990386 ]]
b1=[[ 0.00196161]
 [-0.00495221]
 [-0.000104  ]
 [-0.00249698]
 [-0.00052502]
 [-0.00504953]
 [-0.00458132]
 [ 0.00055554]
 [ 0.00700574]]
W2=[[-0.75073753 -0.14044602  1.41366374  0.52357817  0.78671398  0.56924779
  -0.09727499  0.18355285  0.23524491]]
b2=[[0.00213001]]
-val:
W1=[[-0.24003021 -0.2083404 ]
 [ 1.27093773  0.04147215]
 [ 0.19454277  0.24000448]
 [ 0.62374422 -0.22278188]
 [ 0.21630571  0.21675307]
 [ 0.07660006  0.3208313 ]
 [ 0.80044974 -0.8469555 ]
 [-0.5188491  -0.9939299 ]
 [ 0.11555097  0.2990386 ]]
b1=[[ 0.00196161]
 [-0.00495221]
 [-0.000104  ]
 [-0.00249698]
 [-0.00052502]
 [-0.00504953]
 [-0.00458132]
 [ 0.00055554]
 [ 0.00700574]]
W2=[[-0.75073753 -0.14044602  1.41366374  0.52357817  0.78671398  0.56924779
  -0.09727499  0.18355285  0.23524491]]
b2=[[0.00213001]]

2024-06-08 03:14:36,968 - INFO - ----Hidden_size 11:
2024-06-08 03:14:36,968 - INFO - Round(1/30)
2024-06-08 03:14:48,183 - INFO - >>training completed		| train loss=0.00020295834062710277, val loss=0.00019597688295995937
2024-06-08 03:14:48,183 - INFO - Round(2/30)
2024-06-08 03:14:59,508 - INFO - >>training completed		| train loss=0.00022109913512641862, val loss=0.00021902684813370998
2024-06-08 03:14:59,508 - INFO - Round(3/30)
2024-06-08 03:15:10,694 - INFO - >>training completed		| train loss=5.9706148137016374e-05, val loss=6.075558942854191e-05
2024-06-08 03:15:10,695 - INFO - Model saved to best_val_model.npz
2024-06-08 03:15:10,696 - INFO - Model saved to best_train_model.npz
2024-06-08 03:15:10,696 - INFO - Round(4/30)
2024-06-08 03:15:21,863 - INFO - >>training completed		| train loss=0.00027225475856939565, val loss=0.0002587528208178474
2024-06-08 03:15:21,864 - INFO - Round(5/30)
2024-06-08 03:15:33,168 - INFO - >>training completed		| train loss=0.00027762533448921317, val loss=0.00025940227201001374
2024-06-08 03:15:33,168 - INFO - Round(6/30)
2024-06-08 03:15:44,467 - INFO - >>training completed		| train loss=0.0005594504894111707, val loss=0.0005517521586750908
2024-06-08 03:15:44,468 - INFO - Round(7/30)
2024-06-08 03:15:55,613 - INFO - >>training completed		| train loss=0.00027662255070744587, val loss=0.00026875191850816093
2024-06-08 03:15:55,614 - INFO - Round(8/30)
2024-06-08 03:16:06,840 - INFO - >>training completed		| train loss=0.0001365234313020388, val loss=0.00013440992004646511
2024-06-08 03:16:06,840 - INFO - Round(9/30)
2024-06-08 03:16:18,045 - INFO - >>training completed		| train loss=0.0006266549483789199, val loss=0.0005947917077532932
2024-06-08 03:16:18,046 - INFO - Round(10/30)
2024-06-08 03:16:29,457 - INFO - >>training completed		| train loss=0.0002444041862975129, val loss=0.00024246825802973524
2024-06-08 03:16:29,457 - INFO - Round(11/30)
2024-06-08 03:16:40,850 - INFO - >>training completed		| train loss=0.00020015839759689055, val loss=0.0001926712616690074
2024-06-08 03:16:40,850 - INFO - Round(12/30)
2024-06-08 03:16:52,072 - INFO - >>training completed		| train loss=0.00032301752811498554, val loss=0.0003202731561835219
2024-06-08 03:16:52,072 - INFO - Round(13/30)
2024-06-08 03:17:03,302 - INFO - >>training completed		| train loss=0.00015911841985153513, val loss=0.00015393356603531183
2024-06-08 03:17:03,302 - INFO - Round(14/30)
2024-06-08 03:17:14,640 - INFO - >>training completed		| train loss=0.0002940298421383411, val loss=0.00027874734145021904
2024-06-08 03:17:14,640 - INFO - Round(15/30)
2024-06-08 03:17:25,870 - INFO - >>training completed		| train loss=8.204885273877157e-05, val loss=8.105215571213498e-05
2024-06-08 03:17:25,870 - INFO - Round(16/30)
2024-06-08 03:17:37,077 - INFO - >>training completed		| train loss=0.00041820617624522334, val loss=0.0003892515163883418
2024-06-08 03:17:37,077 - INFO - Round(17/30)
2024-06-08 03:17:48,350 - INFO - >>training completed		| train loss=0.00029913255959051246, val loss=0.0002843003709586276
2024-06-08 03:17:48,350 - INFO - Round(18/30)
2024-06-08 03:17:59,571 - INFO - >>training completed		| train loss=0.00018716510207199107, val loss=0.00018737707866910505
2024-06-08 03:17:59,571 - INFO - Round(19/30)
2024-06-08 03:18:10,748 - INFO - >>training completed		| train loss=8.355070692499441e-05, val loss=8.116934474980028e-05
2024-06-08 03:18:10,748 - INFO - Round(20/30)
2024-06-08 03:18:22,252 - INFO - >>training completed		| train loss=0.0003061623924053923, val loss=0.00028899919246127236
2024-06-08 03:18:22,252 - INFO - Round(21/30)
2024-06-08 03:18:33,745 - INFO - >>training completed		| train loss=0.00021046130529082049, val loss=0.0002101708754580899
2024-06-08 03:18:33,745 - INFO - Round(22/30)
2024-06-08 03:18:45,258 - INFO - >>training completed		| train loss=0.00015177227737881712, val loss=0.0001493970090802402
2024-06-08 03:18:45,258 - INFO - Round(23/30)
2024-06-08 03:18:56,905 - INFO - >>training completed		| train loss=0.00018975240102098105, val loss=0.00017860305315015154
2024-06-08 03:18:56,905 - INFO - Round(24/30)
2024-06-08 03:19:08,357 - INFO - >>training completed		| train loss=0.0003906995854890339, val loss=0.0003786143935407638
2024-06-08 03:19:08,357 - INFO - Round(25/30)
2024-06-08 03:19:19,648 - INFO - >>training completed		| train loss=0.0005139347917867866, val loss=0.000488512734244004
2024-06-08 03:19:19,649 - INFO - Round(26/30)
2024-06-08 03:19:30,994 - INFO - >>training completed		| train loss=0.00033023744974726394, val loss=0.0003232638206366373
2024-06-08 03:19:30,995 - INFO - Round(27/30)
2024-06-08 03:19:42,301 - INFO - >>training completed		| train loss=9.661495759712388e-05, val loss=9.704490882260456e-05
2024-06-08 03:19:42,301 - INFO - Round(28/30)
2024-06-08 03:19:53,661 - INFO - >>training completed		| train loss=0.0003152453006519478, val loss=0.00030850932565588274
2024-06-08 03:19:53,661 - INFO - Round(29/30)
2024-06-08 03:20:05,054 - INFO - >>training completed		| train loss=0.00026851173989809985, val loss=0.0002638553534078216
2024-06-08 03:20:05,054 - INFO - Round(30/30)
2024-06-08 03:20:16,867 - INFO - >>training completed		| train loss=0.0002008573566363077, val loss=0.00019405689449609646
2024-06-08 03:20:16,867 - INFO - #目前最低損失: train=5.9706148137016374e-05, val=6.075558942854191e-05
2024-06-08 03:20:16,867 - INFO - #目前最佳隱藏層神經元數量: train=11, val=11
2024-06-08 03:20:16,868 - INFO - #目前最佳參數:
-train:
W1=[[-0.24830307 -0.14644044]
 [ 0.15736947  0.23471504]
 [-0.7426249   0.6666563 ]
 [ 0.53757898 -0.31149553]
 [ 0.32326709  0.07014772]
 [-0.34448414 -1.01847345]
 [ 0.12327369  0.26759042]
 [-1.03471111  0.98017243]
 [ 0.23693342  0.15466522]
 [ 0.01881084 -0.36643347]
 [ 1.11131427  0.23559248]]
b1=[[ 0.00464135]
 [-0.00049836]
 [-0.00742986]
 [ 0.00152982]
 [-0.00400769]
 [ 0.00273763]
 [-0.00083726]
 [-0.02489435]
 [ 0.00140847]
 [ 0.00209732]
 [-0.00513215]]
W2=[[-0.81680407  0.6431038   0.2291493   0.45886047  0.35945454  0.14924563
   0.83973383 -0.05821448  0.97874556 -0.68450058 -0.12132182]]
b2=[[0.0039663]]
-val:
W1=[[-0.24830307 -0.14644044]
 [ 0.15736947  0.23471504]
 [-0.7426249   0.6666563 ]
 [ 0.53757898 -0.31149553]
 [ 0.32326709  0.07014772]
 [-0.34448414 -1.01847345]
 [ 0.12327369  0.26759042]
 [-1.03471111  0.98017243]
 [ 0.23693342  0.15466522]
 [ 0.01881084 -0.36643347]
 [ 1.11131427  0.23559248]]
b1=[[ 0.00464135]
 [-0.00049836]
 [-0.00742986]
 [ 0.00152982]
 [-0.00400769]
 [ 0.00273763]
 [-0.00083726]
 [-0.02489435]
 [ 0.00140847]
 [ 0.00209732]
 [-0.00513215]]
W2=[[-0.81680407  0.6431038   0.2291493   0.45886047  0.35945454  0.14924563
   0.83973383 -0.05821448  0.97874556 -0.68450058 -0.12132182]]
b2=[[0.0039663]]

2024-06-08 03:20:16,869 - INFO - ----Hidden_size 12:
2024-06-08 03:20:16,869 - INFO - Round(1/30)
2024-06-08 03:20:28,545 - INFO - >>training completed		| train loss=0.0001402810109793461, val loss=0.0001389023621244644
2024-06-08 03:20:28,545 - INFO - Round(2/30)
2024-06-08 03:20:40,021 - INFO - >>training completed		| train loss=0.0002315056155581685, val loss=0.0002315676092771221
2024-06-08 03:20:40,021 - INFO - Round(3/30)
2024-06-08 03:20:51,288 - INFO - >>training completed		| train loss=0.0003410269684223573, val loss=0.0003210974403776126
2024-06-08 03:20:51,289 - INFO - Round(4/30)
2024-06-08 03:21:02,588 - INFO - >>training completed		| train loss=0.00018180967636853587, val loss=0.00017259389835145583
2024-06-08 03:21:02,589 - INFO - Round(5/30)
2024-06-08 03:21:13,850 - INFO - >>training completed		| train loss=0.00025852933192081865, val loss=0.00025717865082062216
2024-06-08 03:21:13,850 - INFO - Round(6/30)
2024-06-08 03:21:25,162 - INFO - >>training completed		| train loss=7.906096090493804e-05, val loss=7.584023954750452e-05
2024-06-08 03:21:25,163 - INFO - Round(7/30)
2024-06-08 03:21:36,566 - INFO - >>training completed		| train loss=0.00043865608553115616, val loss=0.000427497353174359
2024-06-08 03:21:36,567 - INFO - Round(8/30)
2024-06-08 03:21:47,946 - INFO - >>training completed		| train loss=0.0002461212148443015, val loss=0.00024139337106395141
2024-06-08 03:21:47,946 - INFO - Round(9/30)
2024-06-08 03:21:59,197 - INFO - >>training completed		| train loss=0.00016720894296017686, val loss=0.00016434277232486375
2024-06-08 03:21:59,197 - INFO - Round(10/30)
2024-06-08 03:22:10,638 - INFO - >>training completed		| train loss=6.699813639753229e-05, val loss=6.604758032862954e-05
2024-06-08 03:22:10,639 - INFO - Round(11/30)
2024-06-08 03:22:22,121 - INFO - >>training completed		| train loss=0.00018665319057666982, val loss=0.00018027613357283296
2024-06-08 03:22:22,121 - INFO - Round(12/30)
2024-06-08 03:22:33,652 - INFO - >>training completed		| train loss=0.00028584238206991674, val loss=0.0002673356243205324
2024-06-08 03:22:33,652 - INFO - Round(13/30)
2024-06-08 03:22:44,880 - INFO - >>training completed		| train loss=0.00024484252430447624, val loss=0.00024611550601514427
2024-06-08 03:22:44,880 - INFO - Round(14/30)
2024-06-08 03:22:56,112 - INFO - >>training completed		| train loss=0.00016994429930927368, val loss=0.00016900336247793865
2024-06-08 03:22:56,113 - INFO - Round(15/30)
2024-06-08 03:23:07,329 - INFO - >>training completed		| train loss=0.00033182273953386216, val loss=0.0003156544119948861
2024-06-08 03:23:07,329 - INFO - Round(16/30)
2024-06-08 03:23:18,650 - INFO - >>training completed		| train loss=9.470920512231486e-05, val loss=9.515021031720837e-05
2024-06-08 03:23:18,650 - INFO - Round(17/30)
2024-06-08 03:23:29,846 - INFO - >>training completed		| train loss=0.00048065224167877235, val loss=0.00045876223115273853
2024-06-08 03:23:29,846 - INFO - Round(18/30)
2024-06-08 03:23:41,213 - INFO - >>training completed		| train loss=6.669043778866323e-05, val loss=6.680569402348839e-05
2024-06-08 03:23:41,214 - INFO - Round(19/30)
2024-06-08 03:23:52,462 - INFO - >>training completed		| train loss=0.00017445909340828178, val loss=0.0001709990489674942
2024-06-08 03:23:52,462 - INFO - Round(20/30)
2024-06-08 03:24:03,765 - INFO - >>training completed		| train loss=8.405036228135546e-05, val loss=8.353330619187672e-05
2024-06-08 03:24:03,765 - INFO - Round(21/30)
2024-06-08 03:24:15,225 - INFO - >>training completed		| train loss=0.0003248168125439221, val loss=0.00030686247531550487
2024-06-08 03:24:15,225 - INFO - Round(22/30)
2024-06-08 03:24:26,830 - INFO - >>training completed		| train loss=0.00019199661161788662, val loss=0.00018915917131633806
2024-06-08 03:24:26,830 - INFO - Round(23/30)
2024-06-08 03:24:38,326 - INFO - >>training completed		| train loss=0.00022865171195515145, val loss=0.0002257879647443323
2024-06-08 03:24:38,326 - INFO - Round(24/30)
2024-06-08 03:24:49,863 - INFO - >>training completed		| train loss=0.00015113985239023514, val loss=0.00015031024695066574
2024-06-08 03:24:49,863 - INFO - Round(25/30)
2024-06-08 03:25:01,299 - INFO - >>training completed		| train loss=0.00022642256380892288, val loss=0.0002251379726326366
2024-06-08 03:25:01,299 - INFO - Round(26/30)
2024-06-08 03:25:12,795 - INFO - >>training completed		| train loss=0.0003130220721706938, val loss=0.0003096754167689251
2024-06-08 03:25:12,795 - INFO - Round(27/30)
2024-06-08 03:25:23,763 - INFO - >>training completed		| train loss=0.00015840520770593654, val loss=0.0001524150127834071
2024-06-08 03:25:23,763 - INFO - Round(28/30)
2024-06-08 03:25:34,907 - INFO - >>training completed		| train loss=0.00026175289260147903, val loss=0.0002601775357554169
2024-06-08 03:25:34,908 - INFO - Round(29/30)
2024-06-08 03:25:46,126 - INFO - >>training completed		| train loss=7.125934715889366e-05, val loss=7.166233351851839e-05
2024-06-08 03:25:46,126 - INFO - Round(30/30)
2024-06-08 03:25:57,349 - INFO - >>training completed		| train loss=0.00033419851488590167, val loss=0.00033326978900280935
2024-06-08 03:25:57,349 - INFO - #目前最低損失: train=5.9706148137016374e-05, val=6.075558942854191e-05
2024-06-08 03:25:57,350 - INFO - #目前最佳隱藏層神經元數量: train=11, val=11
2024-06-08 03:25:57,351 - INFO - #目前最佳參數:
-train:
W1=[[-0.24830307 -0.14644044]
 [ 0.15736947  0.23471504]
 [-0.7426249   0.6666563 ]
 [ 0.53757898 -0.31149553]
 [ 0.32326709  0.07014772]
 [-0.34448414 -1.01847345]
 [ 0.12327369  0.26759042]
 [-1.03471111  0.98017243]
 [ 0.23693342  0.15466522]
 [ 0.01881084 -0.36643347]
 [ 1.11131427  0.23559248]]
b1=[[ 0.00464135]
 [-0.00049836]
 [-0.00742986]
 [ 0.00152982]
 [-0.00400769]
 [ 0.00273763]
 [-0.00083726]
 [-0.02489435]
 [ 0.00140847]
 [ 0.00209732]
 [-0.00513215]]
W2=[[-0.81680407  0.6431038   0.2291493   0.45886047  0.35945454  0.14924563
   0.83973383 -0.05821448  0.97874556 -0.68450058 -0.12132182]]
b2=[[0.0039663]]
-val:
W1=[[-0.24830307 -0.14644044]
 [ 0.15736947  0.23471504]
 [-0.7426249   0.6666563 ]
 [ 0.53757898 -0.31149553]
 [ 0.32326709  0.07014772]
 [-0.34448414 -1.01847345]
 [ 0.12327369  0.26759042]
 [-1.03471111  0.98017243]
 [ 0.23693342  0.15466522]
 [ 0.01881084 -0.36643347]
 [ 1.11131427  0.23559248]]
b1=[[ 0.00464135]
 [-0.00049836]
 [-0.00742986]
 [ 0.00152982]
 [-0.00400769]
 [ 0.00273763]
 [-0.00083726]
 [-0.02489435]
 [ 0.00140847]
 [ 0.00209732]
 [-0.00513215]]
W2=[[-0.81680407  0.6431038   0.2291493   0.45886047  0.35945454  0.14924563
   0.83973383 -0.05821448  0.97874556 -0.68450058 -0.12132182]]
b2=[[0.0039663]]

2024-06-08 03:25:57,352 - INFO - ----Hidden_size 13:
2024-06-08 03:25:57,352 - INFO - Round(1/30)
2024-06-08 03:26:08,677 - INFO - >>training completed		| train loss=0.00022407383797876793, val loss=0.0002135693501806246
2024-06-08 03:26:08,678 - INFO - Round(2/30)
2024-06-08 03:26:20,023 - INFO - >>training completed		| train loss=9.396392769091909e-05, val loss=9.392877935630939e-05
2024-06-08 03:26:20,024 - INFO - Round(3/30)
2024-06-08 03:26:31,615 - INFO - >>training completed		| train loss=0.00019548411194722027, val loss=0.00019109766610857665
2024-06-08 03:26:31,615 - INFO - Round(4/30)
2024-06-08 03:26:43,224 - INFO - >>training completed		| train loss=0.00013638112508771816, val loss=0.00013485742044449733
2024-06-08 03:26:43,224 - INFO - Round(5/30)
2024-06-08 03:26:54,498 - INFO - >>training completed		| train loss=0.0002293571171197389, val loss=0.00022388013143151685
2024-06-08 03:26:54,499 - INFO - Round(6/30)
2024-06-08 03:27:05,733 - INFO - >>training completed		| train loss=0.0001747839360007858, val loss=0.0001716096084266053
2024-06-08 03:27:05,733 - INFO - Round(7/30)
2024-06-08 03:27:16,954 - INFO - >>training completed		| train loss=8.927656729961206e-05, val loss=9.019807042788942e-05
2024-06-08 03:27:16,954 - INFO - Round(8/30)
2024-06-08 03:27:28,312 - INFO - >>training completed		| train loss=0.00032398871920564896, val loss=0.00030943321596698395
2024-06-08 03:27:28,312 - INFO - Round(9/30)
2024-06-08 03:27:39,671 - INFO - >>training completed		| train loss=0.0002574775126628857, val loss=0.00024136223592641793
2024-06-08 03:27:39,671 - INFO - Round(10/30)
2024-06-08 03:27:51,549 - INFO - >>training completed		| train loss=4.003762083781347e-05, val loss=3.995403247204243e-05
2024-06-08 03:27:51,550 - INFO - Model saved to best_val_model.npz
2024-06-08 03:27:51,550 - INFO - Model saved to best_train_model.npz
2024-06-08 03:27:51,551 - INFO - Round(11/30)
2024-06-08 03:28:02,439 - INFO - >>training completed		| train loss=0.00020168965176156005, val loss=0.0002021829210435943
2024-06-08 03:28:02,440 - INFO - Round(12/30)
2024-06-08 03:28:13,204 - INFO - >>training completed		| train loss=0.0003379983693520282, val loss=0.0003160877478415325
2024-06-08 03:28:13,205 - INFO - Round(13/30)
2024-06-08 03:28:23,868 - INFO - >>training completed		| train loss=0.0002670217347235038, val loss=0.0002626384406967724
2024-06-08 03:28:23,868 - INFO - Round(14/30)
2024-06-08 03:28:34,958 - INFO - >>training completed		| train loss=0.000129910510465227, val loss=0.00012742307573484934
2024-06-08 03:28:34,958 - INFO - Round(15/30)
2024-06-08 03:28:45,944 - INFO - >>training completed		| train loss=0.00013840038932589084, val loss=0.0001326754664564659
2024-06-08 03:28:45,944 - INFO - Round(16/30)
2024-06-08 03:28:56,702 - INFO - >>training completed		| train loss=6.319449556352922e-05, val loss=6.36666238239692e-05
2024-06-08 03:28:56,702 - INFO - Round(17/30)
2024-06-08 03:29:07,342 - INFO - >>training completed		| train loss=4.4236308085211566e-05, val loss=4.305708266702759e-05
2024-06-08 03:29:07,342 - INFO - Round(18/30)
2024-06-08 03:29:17,945 - INFO - >>training completed		| train loss=0.00016964639446707657, val loss=0.00017070586264487816
2024-06-08 03:29:17,945 - INFO - Round(19/30)
2024-06-08 03:29:28,500 - INFO - >>training completed		| train loss=0.0002048862816116767, val loss=0.00020485176736933822
2024-06-08 03:29:28,500 - INFO - Round(20/30)
2024-06-08 03:29:39,388 - INFO - >>training completed		| train loss=0.00035955272478531295, val loss=0.000358748259308083
2024-06-08 03:29:39,388 - INFO - Round(21/30)
2024-06-08 03:29:50,039 - INFO - >>training completed		| train loss=0.00011527791238123254, val loss=0.00011603168569467458
2024-06-08 03:29:50,039 - INFO - Round(22/30)
2024-06-08 03:30:00,731 - INFO - >>training completed		| train loss=0.00019535836174181277, val loss=0.0001952412830424412
2024-06-08 03:30:00,731 - INFO - Round(23/30)
2024-06-08 03:30:11,506 - INFO - >>training completed		| train loss=0.00014876529850774516, val loss=0.0001408364998080348
2024-06-08 03:30:11,507 - INFO - Round(24/30)
2024-06-08 03:30:22,429 - INFO - >>training completed		| train loss=9.634830896223563e-05, val loss=9.624370146004977e-05
2024-06-08 03:30:22,429 - INFO - Round(25/30)
2024-06-08 03:30:33,628 - INFO - >>training completed		| train loss=8.773842114283766e-05, val loss=8.908095214569526e-05
2024-06-08 03:30:33,628 - INFO - Round(26/30)
2024-06-08 03:30:44,391 - INFO - >>training completed		| train loss=8.506090857229492e-05, val loss=8.265087848435261e-05
2024-06-08 03:30:44,391 - INFO - Round(27/30)
2024-06-08 03:30:55,268 - INFO - >>training completed		| train loss=7.470372450855709e-05, val loss=7.472418702034017e-05
2024-06-08 03:30:55,268 - INFO - Round(28/30)
2024-06-08 03:31:06,212 - INFO - >>training completed		| train loss=8.487008678668228e-05, val loss=8.656483237491591e-05
2024-06-08 03:31:06,212 - INFO - Round(29/30)
2024-06-08 03:31:16,891 - INFO - >>training completed		| train loss=0.00019141142810607013, val loss=0.00018272391807171788
2024-06-08 03:31:16,892 - INFO - Round(30/30)
2024-06-08 03:31:27,573 - INFO - >>training completed		| train loss=0.00018514311439621632, val loss=0.00018116981140449303
2024-06-08 03:31:27,573 - INFO - #目前最低損失: train=4.003762083781347e-05, val=3.995403247204243e-05
2024-06-08 03:31:27,573 - INFO - #目前最佳隱藏層神經元數量: train=13, val=13
2024-06-08 03:31:27,574 - INFO - #目前最佳參數:
-train:
W1=[[ 0.20837252  0.06753717]
 [-0.14296398  0.39497908]
 [ 0.22966747  0.16746228]
 [-0.20159043 -0.21830756]
 [-0.28510049  0.26181504]
 [ 0.13556011  0.252373  ]
 [ 0.24496298  0.72778247]
 [ 0.00887322  0.29709613]
 [ 0.97730384  0.28429714]
 [-0.10250484 -0.25886682]
 [-0.43313168  0.01686621]
 [ 0.21647284  0.21586387]
 [-0.1432577  -0.23417335]]
b1=[[ 1.80000587e-03]
 [ 7.17807295e-03]
 [ 6.25316935e-05]
 [ 2.83326832e-03]
 [-3.77557181e-03]
 [ 1.73117162e-03]
 [ 1.61267711e-04]
 [-3.02472406e-02]
 [-2.01592124e-03]
 [ 3.96751401e-04]
 [ 1.26292707e-03]
 [-7.65266609e-04]
 [-1.04935252e-03]]
W2=[[ 0.27029993  0.32827802  0.88220182 -0.34871437 -0.01006072  0.39729673
  -0.24379516  0.16694958 -0.18184862 -0.48123543 -0.71624928  0.57974472
  -0.7341613 ]]
b2=[[0.00211387]]
-val:
W1=[[ 0.20837252  0.06753717]
 [-0.14296398  0.39497908]
 [ 0.22966747  0.16746228]
 [-0.20159043 -0.21830756]
 [-0.28510049  0.26181504]
 [ 0.13556011  0.252373  ]
 [ 0.24496298  0.72778247]
 [ 0.00887322  0.29709613]
 [ 0.97730384  0.28429714]
 [-0.10250484 -0.25886682]
 [-0.43313168  0.01686621]
 [ 0.21647284  0.21586387]
 [-0.1432577  -0.23417335]]
b1=[[ 1.80000587e-03]
 [ 7.17807295e-03]
 [ 6.25316935e-05]
 [ 2.83326832e-03]
 [-3.77557181e-03]
 [ 1.73117162e-03]
 [ 1.61267711e-04]
 [-3.02472406e-02]
 [-2.01592124e-03]
 [ 3.96751401e-04]
 [ 1.26292707e-03]
 [-7.65266609e-04]
 [-1.04935252e-03]]
W2=[[ 0.27029993  0.32827802  0.88220182 -0.34871437 -0.01006072  0.39729673
  -0.24379516  0.16694958 -0.18184862 -0.48123543 -0.71624928  0.57974472
  -0.7341613 ]]
b2=[[0.00211387]]

2024-06-08 03:31:27,576 - INFO - ----Hidden_size 14:
2024-06-08 03:31:27,576 - INFO - Round(1/30)
2024-06-08 03:31:38,401 - INFO - >>training completed		| train loss=0.00011543745123795335, val loss=0.00011756942732143896
2024-06-08 03:31:38,401 - INFO - Round(2/30)
2024-06-08 03:31:49,111 - INFO - >>training completed		| train loss=0.00023390102659942886, val loss=0.0002264852641316319
2024-06-08 03:31:49,111 - INFO - Round(3/30)
2024-06-08 03:32:00,003 - INFO - >>training completed		| train loss=0.00017376360553378504, val loss=0.00016838447826820072
2024-06-08 03:32:00,003 - INFO - Round(4/30)
2024-06-08 03:32:11,026 - INFO - >>training completed		| train loss=0.0002970504363063019, val loss=0.00029323540933861626
2024-06-08 03:32:11,026 - INFO - Round(5/30)
2024-06-08 03:32:22,424 - INFO - >>training completed		| train loss=4.801322033979096e-05, val loss=4.784312903561085e-05
2024-06-08 03:32:22,424 - INFO - Round(6/30)
2024-06-08 03:32:33,620 - INFO - >>training completed		| train loss=0.00012497636381180523, val loss=0.00011681191305090865
2024-06-08 03:32:33,621 - INFO - Round(7/30)
2024-06-08 03:32:44,539 - INFO - >>training completed		| train loss=7.265944142781848e-05, val loss=7.450207429560865e-05
2024-06-08 03:32:44,540 - INFO - Round(8/30)
2024-06-08 03:32:55,235 - INFO - >>training completed		| train loss=0.00010902084786985309, val loss=0.00010997331258624962
2024-06-08 03:32:55,235 - INFO - Round(9/30)
2024-06-08 03:33:06,249 - INFO - >>training completed		| train loss=0.00022420389708240597, val loss=0.00021326226813237937
2024-06-08 03:33:06,249 - INFO - Round(10/30)
2024-06-08 03:33:16,884 - INFO - >>training completed		| train loss=0.00013708341263203607, val loss=0.0001336416355504418
2024-06-08 03:33:16,884 - INFO - Round(11/30)
2024-06-08 03:33:27,882 - INFO - >>training completed		| train loss=0.00017366922135316761, val loss=0.00016167219304443205
2024-06-08 03:33:27,883 - INFO - Round(12/30)
2024-06-08 03:33:39,046 - INFO - >>training completed		| train loss=0.00010777768131877486, val loss=0.00010910548232725677
2024-06-08 03:33:39,046 - INFO - Round(13/30)
2024-06-08 03:33:49,707 - INFO - >>training completed		| train loss=0.00018335277876760362, val loss=0.0001821441480237584
2024-06-08 03:33:49,707 - INFO - Round(14/30)
2024-06-08 03:34:00,301 - INFO - >>training completed		| train loss=0.00010494523405536098, val loss=0.00010232221489392973
2024-06-08 03:34:00,301 - INFO - Round(15/30)
2024-06-08 03:34:10,951 - INFO - >>training completed		| train loss=0.00015178167144093728, val loss=0.00014936365329468664
2024-06-08 03:34:10,951 - INFO - Round(16/30)
2024-06-08 03:34:21,690 - INFO - >>training completed		| train loss=0.00013477116943631082, val loss=0.0001330607570463254
2024-06-08 03:34:21,690 - INFO - Round(17/30)
2024-06-08 03:34:32,331 - INFO - >>training completed		| train loss=0.00012002716120250623, val loss=0.00011690077724912434
2024-06-08 03:34:32,331 - INFO - Round(18/30)
2024-06-08 03:34:42,973 - INFO - >>training completed		| train loss=0.0002021589953481411, val loss=0.00019011453892215236
2024-06-08 03:34:42,973 - INFO - Round(19/30)
2024-06-08 03:34:53,488 - INFO - >>training completed		| train loss=7.359824142996477e-05, val loss=7.546664932256323e-05
2024-06-08 03:34:53,488 - INFO - Round(20/30)
2024-06-08 03:35:04,451 - INFO - >>training completed		| train loss=0.0001548260188783541, val loss=0.00014611027729369972
2024-06-08 03:35:04,451 - INFO - Round(21/30)
2024-06-08 03:35:15,336 - INFO - >>training completed		| train loss=8.399713554770652e-05, val loss=8.51255745382574e-05
2024-06-08 03:35:15,336 - INFO - Round(22/30)
2024-06-08 03:35:26,190 - INFO - >>training completed		| train loss=0.0001870593959134641, val loss=0.00018739218648465556
2024-06-08 03:35:26,190 - INFO - Round(23/30)
2024-06-08 03:35:36,872 - INFO - >>training completed		| train loss=0.00016055444278832557, val loss=0.00015505147782527342
2024-06-08 03:35:36,872 - INFO - Round(24/30)
2024-06-08 03:35:47,645 - INFO - >>training completed		| train loss=8.677945552479008e-05, val loss=8.661597564427065e-05
2024-06-08 03:35:47,646 - INFO - Round(25/30)
2024-06-08 03:35:58,285 - INFO - >>training completed		| train loss=8.718783568693509e-05, val loss=8.748994654266127e-05
2024-06-08 03:35:58,285 - INFO - Round(26/30)
2024-06-08 03:36:08,982 - INFO - >>training completed		| train loss=0.0002195519870087556, val loss=0.0002202996391061122
2024-06-08 03:36:08,982 - INFO - Round(27/30)
2024-06-08 03:36:20,213 - INFO - >>training completed		| train loss=8.252270566437542e-05, val loss=8.088084816781555e-05
2024-06-08 03:36:20,213 - INFO - Round(28/30)
2024-06-08 03:36:31,239 - INFO - >>training completed		| train loss=0.00020244597478647972, val loss=0.00020224877988545182
2024-06-08 03:36:31,240 - INFO - Round(29/30)
2024-06-08 03:36:41,946 - INFO - >>training completed		| train loss=0.0002565208765885091, val loss=0.00025259283310446453
2024-06-08 03:36:41,946 - INFO - Round(30/30)
2024-06-08 03:36:52,661 - INFO - >>training completed		| train loss=7.668593237263127e-05, val loss=7.561960025250431e-05
2024-06-08 03:36:52,661 - INFO - #目前最低損失: train=4.003762083781347e-05, val=3.995403247204243e-05
2024-06-08 03:36:52,662 - INFO - #目前最佳隱藏層神經元數量: train=13, val=13
2024-06-08 03:36:52,663 - INFO - #目前最佳參數:
-train:
W1=[[ 0.20837252  0.06753717]
 [-0.14296398  0.39497908]
 [ 0.22966747  0.16746228]
 [-0.20159043 -0.21830756]
 [-0.28510049  0.26181504]
 [ 0.13556011  0.252373  ]
 [ 0.24496298  0.72778247]
 [ 0.00887322  0.29709613]
 [ 0.97730384  0.28429714]
 [-0.10250484 -0.25886682]
 [-0.43313168  0.01686621]
 [ 0.21647284  0.21586387]
 [-0.1432577  -0.23417335]]
b1=[[ 1.80000587e-03]
 [ 7.17807295e-03]
 [ 6.25316935e-05]
 [ 2.83326832e-03]
 [-3.77557181e-03]
 [ 1.73117162e-03]
 [ 1.61267711e-04]
 [-3.02472406e-02]
 [-2.01592124e-03]
 [ 3.96751401e-04]
 [ 1.26292707e-03]
 [-7.65266609e-04]
 [-1.04935252e-03]]
W2=[[ 0.27029993  0.32827802  0.88220182 -0.34871437 -0.01006072  0.39729673
  -0.24379516  0.16694958 -0.18184862 -0.48123543 -0.71624928  0.57974472
  -0.7341613 ]]
b2=[[0.00211387]]
-val:
W1=[[ 0.20837252  0.06753717]
 [-0.14296398  0.39497908]
 [ 0.22966747  0.16746228]
 [-0.20159043 -0.21830756]
 [-0.28510049  0.26181504]
 [ 0.13556011  0.252373  ]
 [ 0.24496298  0.72778247]
 [ 0.00887322  0.29709613]
 [ 0.97730384  0.28429714]
 [-0.10250484 -0.25886682]
 [-0.43313168  0.01686621]
 [ 0.21647284  0.21586387]
 [-0.1432577  -0.23417335]]
b1=[[ 1.80000587e-03]
 [ 7.17807295e-03]
 [ 6.25316935e-05]
 [ 2.83326832e-03]
 [-3.77557181e-03]
 [ 1.73117162e-03]
 [ 1.61267711e-04]
 [-3.02472406e-02]
 [-2.01592124e-03]
 [ 3.96751401e-04]
 [ 1.26292707e-03]
 [-7.65266609e-04]
 [-1.04935252e-03]]
W2=[[ 0.27029993  0.32827802  0.88220182 -0.34871437 -0.01006072  0.39729673
  -0.24379516  0.16694958 -0.18184862 -0.48123543 -0.71624928  0.57974472
  -0.7341613 ]]
b2=[[0.00211387]]

2024-06-08 03:36:52,664 - INFO - ----Hidden_size 15:
2024-06-08 03:36:52,664 - INFO - Round(1/30)
2024-06-08 03:37:03,465 - INFO - >>training completed		| train loss=0.00021999131027418517, val loss=0.00021889380187576084
2024-06-08 03:37:03,465 - INFO - Round(2/30)
2024-06-08 03:37:14,131 - INFO - >>training completed		| train loss=5.16475307604803e-05, val loss=5.0536682399662736e-05
2024-06-08 03:37:14,131 - INFO - Round(3/30)
2024-06-08 03:37:24,711 - INFO - >>training completed		| train loss=0.00026054623067325514, val loss=0.0002464428340913672
2024-06-08 03:37:24,711 - INFO - Round(4/30)
2024-06-08 03:37:35,461 - INFO - >>training completed		| train loss=7.132325865843394e-05, val loss=7.261453723758975e-05
2024-06-08 03:37:35,461 - INFO - Round(5/30)
2024-06-08 03:37:46,016 - INFO - >>training completed		| train loss=0.0001632024873482061, val loss=0.0001579869816626836
2024-06-08 03:37:46,016 - INFO - Round(6/30)
2024-06-08 03:37:56,461 - INFO - >>early stopped at epoch 10	| train loss=5.7724329718665583e-05, val loss=5.8253835378541176e-05
2024-06-08 03:37:56,461 - INFO - Round(7/30)
2024-06-08 03:38:07,188 - INFO - >>training completed		| train loss=0.00011399584075298547, val loss=0.00011323362790032791
2024-06-08 03:38:07,188 - INFO - Round(8/30)
2024-06-08 03:38:18,607 - INFO - >>training completed		| train loss=9.199109060938201e-05, val loss=9.249958398510655e-05
2024-06-08 03:38:18,607 - INFO - Round(9/30)
2024-06-08 03:38:29,946 - INFO - >>training completed		| train loss=8.737014726881751e-05, val loss=8.802575428154163e-05
2024-06-08 03:38:29,946 - INFO - Round(10/30)
2024-06-08 03:38:40,878 - INFO - >>training completed		| train loss=9.500971974673569e-05, val loss=9.751413834240841e-05
2024-06-08 03:38:40,878 - INFO - Round(11/30)
2024-06-08 03:38:51,722 - INFO - >>training completed		| train loss=0.00022745505646356556, val loss=0.00021667378662880692
2024-06-08 03:38:51,722 - INFO - Round(12/30)
2024-06-08 03:39:02,252 - INFO - >>training completed		| train loss=8.67482813299646e-05, val loss=8.801161897711945e-05
2024-06-08 03:39:02,252 - INFO - Round(13/30)
2024-06-08 03:39:13,014 - INFO - >>training completed		| train loss=0.0001833017416507061, val loss=0.00017642723147550822
2024-06-08 03:39:13,014 - INFO - Round(14/30)
2024-06-08 03:39:23,925 - INFO - >>training completed		| train loss=0.00040209448763248667, val loss=0.0003858004242205593
2024-06-08 03:39:23,925 - INFO - Round(15/30)
2024-06-08 03:39:34,959 - INFO - >>training completed		| train loss=0.00014500320732812938, val loss=0.00014448038778643065
2024-06-08 03:39:34,959 - INFO - Round(16/30)
2024-06-08 03:39:45,685 - INFO - >>training completed		| train loss=8.629251877636686e-05, val loss=8.748973662464648e-05
2024-06-08 03:39:45,685 - INFO - Round(17/30)
2024-06-08 03:39:56,541 - INFO - >>training completed		| train loss=8.503528863675272e-05, val loss=8.561821165160793e-05
2024-06-08 03:39:56,541 - INFO - Round(18/30)
2024-06-08 03:40:07,366 - INFO - >>training completed		| train loss=0.00013538328702665013, val loss=0.0001358593787646307
2024-06-08 03:40:07,366 - INFO - Round(19/30)
2024-06-08 03:40:18,178 - INFO - >>training completed		| train loss=6.446486297836897e-05, val loss=6.415314231707655e-05
2024-06-08 03:40:18,178 - INFO - Round(20/30)
2024-06-08 03:40:29,006 - INFO - >>training completed		| train loss=8.200127937981327e-05, val loss=8.136220863985577e-05
2024-06-08 03:40:29,007 - INFO - Round(21/30)
2024-06-08 03:40:40,030 - INFO - >>training completed		| train loss=0.00026783588672415684, val loss=0.0002686568116318539
2024-06-08 03:40:40,030 - INFO - Round(22/30)
2024-06-08 03:40:50,985 - INFO - >>training completed		| train loss=9.55019858361897e-05, val loss=9.46715093571396e-05
2024-06-08 03:40:50,985 - INFO - Round(23/30)
2024-06-08 03:41:02,276 - INFO - >>training completed		| train loss=0.00011680642012219747, val loss=0.0001166303700361414
2024-06-08 03:41:02,276 - INFO - Round(24/30)
2024-06-08 03:41:13,038 - INFO - >>training completed		| train loss=0.000158620841458961, val loss=0.00015063336736173368
2024-06-08 03:41:13,038 - INFO - Round(25/30)
2024-06-08 03:41:23,725 - INFO - >>training completed		| train loss=0.00015491960249144104, val loss=0.0001526939684326047
2024-06-08 03:41:23,725 - INFO - Round(26/30)
2024-06-08 03:41:33,236 - INFO - >>early stopped at epoch 9	| train loss=0.0002302460695624523, val loss=0.0002209829529652157
2024-06-08 03:41:33,236 - INFO - Round(27/30)
2024-06-08 03:41:43,765 - INFO - >>training completed		| train loss=0.00020079136664578984, val loss=0.00019684465760958089
2024-06-08 03:41:43,765 - INFO - Round(28/30)
2024-06-08 03:41:54,469 - INFO - >>training completed		| train loss=0.00017376982583020505, val loss=0.0001680972878170143
2024-06-08 03:41:54,469 - INFO - Round(29/30)
2024-06-08 03:42:05,200 - INFO - >>training completed		| train loss=0.00011150729154465437, val loss=0.00011102566372816073
2024-06-08 03:42:05,201 - INFO - Round(30/30)
2024-06-08 03:42:16,096 - INFO - >>training completed		| train loss=0.00018773311294130834, val loss=0.0001843885740668732
2024-06-08 03:42:16,096 - INFO - #目前最低損失: train=4.003762083781347e-05, val=3.995403247204243e-05
2024-06-08 03:42:16,096 - INFO - #目前最佳隱藏層神經元數量: train=13, val=13
2024-06-08 03:42:16,097 - INFO - #目前最佳參數:
-train:
W1=[[ 0.20837252  0.06753717]
 [-0.14296398  0.39497908]
 [ 0.22966747  0.16746228]
 [-0.20159043 -0.21830756]
 [-0.28510049  0.26181504]
 [ 0.13556011  0.252373  ]
 [ 0.24496298  0.72778247]
 [ 0.00887322  0.29709613]
 [ 0.97730384  0.28429714]
 [-0.10250484 -0.25886682]
 [-0.43313168  0.01686621]
 [ 0.21647284  0.21586387]
 [-0.1432577  -0.23417335]]
b1=[[ 1.80000587e-03]
 [ 7.17807295e-03]
 [ 6.25316935e-05]
 [ 2.83326832e-03]
 [-3.77557181e-03]
 [ 1.73117162e-03]
 [ 1.61267711e-04]
 [-3.02472406e-02]
 [-2.01592124e-03]
 [ 3.96751401e-04]
 [ 1.26292707e-03]
 [-7.65266609e-04]
 [-1.04935252e-03]]
W2=[[ 0.27029993  0.32827802  0.88220182 -0.34871437 -0.01006072  0.39729673
  -0.24379516  0.16694958 -0.18184862 -0.48123543 -0.71624928  0.57974472
  -0.7341613 ]]
b2=[[0.00211387]]
-val:
W1=[[ 0.20837252  0.06753717]
 [-0.14296398  0.39497908]
 [ 0.22966747  0.16746228]
 [-0.20159043 -0.21830756]
 [-0.28510049  0.26181504]
 [ 0.13556011  0.252373  ]
 [ 0.24496298  0.72778247]
 [ 0.00887322  0.29709613]
 [ 0.97730384  0.28429714]
 [-0.10250484 -0.25886682]
 [-0.43313168  0.01686621]
 [ 0.21647284  0.21586387]
 [-0.1432577  -0.23417335]]
b1=[[ 1.80000587e-03]
 [ 7.17807295e-03]
 [ 6.25316935e-05]
 [ 2.83326832e-03]
 [-3.77557181e-03]
 [ 1.73117162e-03]
 [ 1.61267711e-04]
 [-3.02472406e-02]
 [-2.01592124e-03]
 [ 3.96751401e-04]
 [ 1.26292707e-03]
 [-7.65266609e-04]
 [-1.04935252e-03]]
W2=[[ 0.27029993  0.32827802  0.88220182 -0.34871437 -0.01006072  0.39729673
  -0.24379516  0.16694958 -0.18184862 -0.48123543 -0.71624928  0.57974472
  -0.7341613 ]]
b2=[[0.00211387]]

2024-06-08 03:42:16,098 - INFO - ----Hidden_size 16:
2024-06-08 03:42:16,098 - INFO - Round(1/30)
2024-06-08 03:42:27,240 - INFO - >>training completed		| train loss=8.084385681211855e-05, val loss=8.292281053519459e-05
2024-06-08 03:42:27,240 - INFO - Round(2/30)
2024-06-08 03:42:38,174 - INFO - >>training completed		| train loss=0.0001909914525191307, val loss=0.00019119608161742316
2024-06-08 03:42:38,174 - INFO - Round(3/30)
2024-06-08 03:42:48,871 - INFO - >>training completed		| train loss=0.00012016350651690923, val loss=0.00011843660147634986
2024-06-08 03:42:48,871 - INFO - Round(4/30)
2024-06-08 03:42:59,517 - INFO - >>training completed		| train loss=0.0001742805284306944, val loss=0.0001688463555233117
2024-06-08 03:42:59,517 - INFO - Round(5/30)
2024-06-08 03:43:10,358 - INFO - >>training completed		| train loss=6.591836300102762e-05, val loss=6.698726706345326e-05
2024-06-08 03:43:10,358 - INFO - Round(6/30)
2024-06-08 03:43:20,992 - INFO - >>training completed		| train loss=0.00010460068067879825, val loss=0.00010539314211811481
2024-06-08 03:43:20,992 - INFO - Round(7/30)
2024-06-08 03:43:31,515 - INFO - >>training completed		| train loss=0.00010277794693080933, val loss=0.00010087193083993724
2024-06-08 03:43:31,515 - INFO - Round(8/30)
2024-06-08 03:43:42,295 - INFO - >>training completed		| train loss=0.00010448238061395316, val loss=0.0001053566763127161
2024-06-08 03:43:42,295 - INFO - Round(9/30)
2024-06-08 03:43:53,000 - INFO - >>training completed		| train loss=0.0002725239995230281, val loss=0.00026886443712263443
2024-06-08 03:43:53,000 - INFO - Round(10/30)
2024-06-08 03:44:03,681 - INFO - >>training completed		| train loss=0.00011025892002823365, val loss=0.00011059416088837923
2024-06-08 03:44:03,681 - INFO - Round(11/30)
2024-06-08 03:44:14,718 - INFO - >>training completed		| train loss=8.555325951558435e-05, val loss=8.551119762649715e-05
2024-06-08 03:44:14,718 - INFO - Round(12/30)
2024-06-08 03:44:26,330 - INFO - >>training completed		| train loss=6.746127495310706e-05, val loss=6.73083386989109e-05
2024-06-08 03:44:26,330 - INFO - Round(13/30)
2024-06-08 03:44:38,168 - INFO - >>training completed		| train loss=8.895285908294351e-05, val loss=8.914966869912453e-05
2024-06-08 03:44:38,168 - INFO - Round(14/30)
2024-06-08 03:44:48,836 - INFO - >>training completed		| train loss=0.00031630158022842586, val loss=0.000300225949324245
2024-06-08 03:44:48,836 - INFO - Round(15/30)
2024-06-08 03:44:59,576 - INFO - >>training completed		| train loss=5.06113523465091e-05, val loss=5.066102093809421e-05
2024-06-08 03:44:59,577 - INFO - Round(16/30)
2024-06-08 03:45:10,349 - INFO - >>training completed		| train loss=8.647440884285725e-05, val loss=8.496841117876423e-05
2024-06-08 03:45:10,349 - INFO - Round(17/30)
2024-06-08 03:45:21,332 - INFO - >>training completed		| train loss=8.29093076706225e-05, val loss=8.197050508494406e-05
2024-06-08 03:45:21,332 - INFO - Round(18/30)
2024-06-08 03:45:32,288 - INFO - >>training completed		| train loss=0.00011088447489015158, val loss=0.00010967391812231187
2024-06-08 03:45:32,288 - INFO - Round(19/30)
2024-06-08 03:45:43,447 - INFO - >>training completed		| train loss=0.0001626741783552789, val loss=0.00016055930992796397
2024-06-08 03:45:43,447 - INFO - Round(20/30)
2024-06-08 03:45:54,264 - INFO - >>training completed		| train loss=9.551634715376412e-05, val loss=9.529184863280513e-05
2024-06-08 03:45:54,264 - INFO - Round(21/30)
2024-06-08 03:46:05,212 - INFO - >>training completed		| train loss=0.0001381979884503749, val loss=0.00013478383500243644
2024-06-08 03:46:05,212 - INFO - Round(22/30)
2024-06-08 03:46:16,382 - INFO - >>training completed		| train loss=0.00011011980615972996, val loss=0.00010888240520510812
2024-06-08 03:46:16,382 - INFO - Round(23/30)
2024-06-08 03:46:27,892 - INFO - >>training completed		| train loss=0.0001225784375160838, val loss=0.00012269429109007513
2024-06-08 03:46:27,892 - INFO - Round(24/30)
2024-06-08 03:46:39,157 - INFO - >>training completed		| train loss=0.00012261568655799027, val loss=0.00011915464977605694
2024-06-08 03:46:39,157 - INFO - Round(25/30)
2024-06-08 03:46:49,986 - INFO - >>training completed		| train loss=0.00015437372267831272, val loss=0.000153071523411765
2024-06-08 03:46:49,987 - INFO - Round(26/30)
2024-06-08 03:47:00,780 - INFO - >>training completed		| train loss=9.100871665533227e-05, val loss=9.1118827526304e-05
2024-06-08 03:47:00,780 - INFO - Round(27/30)
2024-06-08 03:47:11,424 - INFO - >>training completed		| train loss=0.00010675017339160242, val loss=0.0001057635407380112
2024-06-08 03:47:11,424 - INFO - Round(28/30)
2024-06-08 03:47:21,996 - INFO - >>training completed		| train loss=0.00014528208608924762, val loss=0.00013946161714921198
2024-06-08 03:47:21,996 - INFO - Round(29/30)
2024-06-08 03:47:32,679 - INFO - >>training completed		| train loss=0.00022729088828819888, val loss=0.00022706606046429795
2024-06-08 03:47:32,679 - INFO - Round(30/30)
2024-06-08 03:47:43,459 - INFO - >>training completed		| train loss=0.00011374441654937759, val loss=0.00011442242033572029
2024-06-08 03:47:43,459 - INFO - #目前最低損失: train=4.003762083781347e-05, val=3.995403247204243e-05
2024-06-08 03:47:43,459 - INFO - #目前最佳隱藏層神經元數量: train=13, val=13
2024-06-08 03:47:43,460 - INFO - #目前最佳參數:
-train:
W1=[[ 0.20837252  0.06753717]
 [-0.14296398  0.39497908]
 [ 0.22966747  0.16746228]
 [-0.20159043 -0.21830756]
 [-0.28510049  0.26181504]
 [ 0.13556011  0.252373  ]
 [ 0.24496298  0.72778247]
 [ 0.00887322  0.29709613]
 [ 0.97730384  0.28429714]
 [-0.10250484 -0.25886682]
 [-0.43313168  0.01686621]
 [ 0.21647284  0.21586387]
 [-0.1432577  -0.23417335]]
b1=[[ 1.80000587e-03]
 [ 7.17807295e-03]
 [ 6.25316935e-05]
 [ 2.83326832e-03]
 [-3.77557181e-03]
 [ 1.73117162e-03]
 [ 1.61267711e-04]
 [-3.02472406e-02]
 [-2.01592124e-03]
 [ 3.96751401e-04]
 [ 1.26292707e-03]
 [-7.65266609e-04]
 [-1.04935252e-03]]
W2=[[ 0.27029993  0.32827802  0.88220182 -0.34871437 -0.01006072  0.39729673
  -0.24379516  0.16694958 -0.18184862 -0.48123543 -0.71624928  0.57974472
  -0.7341613 ]]
b2=[[0.00211387]]
-val:
W1=[[ 0.20837252  0.06753717]
 [-0.14296398  0.39497908]
 [ 0.22966747  0.16746228]
 [-0.20159043 -0.21830756]
 [-0.28510049  0.26181504]
 [ 0.13556011  0.252373  ]
 [ 0.24496298  0.72778247]
 [ 0.00887322  0.29709613]
 [ 0.97730384  0.28429714]
 [-0.10250484 -0.25886682]
 [-0.43313168  0.01686621]
 [ 0.21647284  0.21586387]
 [-0.1432577  -0.23417335]]
b1=[[ 1.80000587e-03]
 [ 7.17807295e-03]
 [ 6.25316935e-05]
 [ 2.83326832e-03]
 [-3.77557181e-03]
 [ 1.73117162e-03]
 [ 1.61267711e-04]
 [-3.02472406e-02]
 [-2.01592124e-03]
 [ 3.96751401e-04]
 [ 1.26292707e-03]
 [-7.65266609e-04]
 [-1.04935252e-03]]
W2=[[ 0.27029993  0.32827802  0.88220182 -0.34871437 -0.01006072  0.39729673
  -0.24379516  0.16694958 -0.18184862 -0.48123543 -0.71624928  0.57974472
  -0.7341613 ]]
b2=[[0.00211387]]

2024-06-08 03:47:43,462 - INFO - ----Hidden_size 17:
2024-06-08 03:47:43,462 - INFO - Round(1/30)
2024-06-08 03:47:54,302 - INFO - >>training completed		| train loss=0.00022659193708874062, val loss=0.00021715708166199725
2024-06-08 03:47:54,303 - INFO - Round(2/30)
2024-06-08 03:48:05,356 - INFO - >>training completed		| train loss=0.00019808209332883495, val loss=0.00019582147498829305
2024-06-08 03:48:05,356 - INFO - Round(3/30)
2024-06-08 03:48:16,326 - INFO - >>training completed		| train loss=0.00019891794204471137, val loss=0.00019266737764864116
2024-06-08 03:48:16,326 - INFO - Round(4/30)
2024-06-08 03:48:26,793 - INFO - >>training completed		| train loss=9.645874247157709e-05, val loss=9.668134821141573e-05
2024-06-08 03:48:26,793 - INFO - Round(5/30)
2024-06-08 03:48:37,412 - INFO - >>training completed		| train loss=0.0001561869938174582, val loss=0.0001549366135996903
2024-06-08 03:48:37,412 - INFO - Round(6/30)
2024-06-08 03:48:48,233 - INFO - >>training completed		| train loss=0.00011146567638800049, val loss=0.00010694680064181118
2024-06-08 03:48:48,233 - INFO - Round(7/30)
2024-06-08 03:48:58,954 - INFO - >>training completed		| train loss=0.00024674282573973195, val loss=0.00023612424537133704
2024-06-08 03:48:58,954 - INFO - Round(8/30)
2024-06-08 03:49:09,642 - INFO - >>training completed		| train loss=7.620494865720215e-05, val loss=7.58225677734102e-05
2024-06-08 03:49:09,642 - INFO - Round(9/30)
2024-06-08 03:49:20,129 - INFO - >>training completed		| train loss=7.804895529088726e-05, val loss=7.879160655503965e-05
2024-06-08 03:49:20,130 - INFO - Round(10/30)
2024-06-08 03:49:30,718 - INFO - >>training completed		| train loss=8.822944089295634e-05, val loss=8.678391138232002e-05
2024-06-08 03:49:30,718 - INFO - Round(11/30)
2024-06-08 03:49:41,384 - INFO - >>training completed		| train loss=0.00016442668222589228, val loss=0.00016192398259544575
2024-06-08 03:49:41,385 - INFO - Round(12/30)
2024-06-08 03:49:51,986 - INFO - >>training completed		| train loss=0.00017023440275423164, val loss=0.00016911364772809748
2024-06-08 03:49:51,986 - INFO - Round(13/30)
2024-06-08 03:50:02,620 - INFO - >>training completed		| train loss=0.00013332474075914913, val loss=0.00013117278010802162
2024-06-08 03:50:02,620 - INFO - Round(14/30)
2024-06-08 03:50:13,542 - INFO - >>training completed		| train loss=8.174335148974182e-05, val loss=8.251070220559185e-05
2024-06-08 03:50:13,542 - INFO - Round(15/30)
2024-06-08 03:50:24,989 - INFO - >>training completed		| train loss=0.00010184622524656942, val loss=0.00010153741335038403
2024-06-08 03:50:24,990 - INFO - Round(16/30)
2024-06-08 03:50:36,421 - INFO - >>training completed		| train loss=8.735937335482342e-05, val loss=8.72316674323034e-05
2024-06-08 03:50:36,421 - INFO - Round(17/30)
2024-06-08 03:50:47,099 - INFO - >>training completed		| train loss=0.00014845597944614154, val loss=0.00014389758896917514
2024-06-08 03:50:47,099 - INFO - Round(18/30)
2024-06-08 03:50:57,717 - INFO - >>training completed		| train loss=0.00023344777511213595, val loss=0.00023337253372268107
2024-06-08 03:50:57,717 - INFO - Round(19/30)
2024-06-08 03:51:08,373 - INFO - >>training completed		| train loss=5.7036597910030766e-05, val loss=5.7048985561098044e-05
2024-06-08 03:51:08,373 - INFO - Round(20/30)
2024-06-08 03:51:19,326 - INFO - >>training completed		| train loss=0.00010283582872214592, val loss=0.00010210159045815765
2024-06-08 03:51:19,326 - INFO - Round(21/30)
2024-06-08 03:51:30,190 - INFO - >>training completed		| train loss=0.00022719041513267875, val loss=0.00021863938948235855
2024-06-08 03:51:30,190 - INFO - Round(22/30)
2024-06-08 03:51:40,995 - INFO - >>training completed		| train loss=0.00024731231241415517, val loss=0.00023947549791878797
2024-06-08 03:51:40,996 - INFO - Round(23/30)
2024-06-08 03:51:51,596 - INFO - >>training completed		| train loss=9.655268148242353e-05, val loss=9.399966768568658e-05
2024-06-08 03:51:51,596 - INFO - Round(24/30)
2024-06-08 03:52:02,285 - INFO - >>training completed		| train loss=0.00015990949225538038, val loss=0.00015634085167608646
2024-06-08 03:52:02,285 - INFO - Round(25/30)
2024-06-08 03:52:13,190 - INFO - >>training completed		| train loss=6.005934063077923e-05, val loss=5.9168970665396544e-05
2024-06-08 03:52:13,190 - INFO - Round(26/30)
2024-06-08 03:52:24,651 - INFO - >>training completed		| train loss=0.00010163085972711329, val loss=9.867763756079015e-05
2024-06-08 03:52:24,651 - INFO - Round(27/30)
2024-06-08 03:52:35,745 - INFO - >>training completed		| train loss=9.850707941765333e-05, val loss=9.713550355450363e-05
2024-06-08 03:52:35,745 - INFO - Round(28/30)
2024-06-08 03:52:46,538 - INFO - >>training completed		| train loss=0.00015425748494013976, val loss=0.00015414766988649226
2024-06-08 03:52:46,538 - INFO - Round(29/30)
2024-06-08 03:52:57,214 - INFO - >>training completed		| train loss=0.00023530498932791523, val loss=0.00022422679153752168
2024-06-08 03:52:57,214 - INFO - Round(30/30)
2024-06-08 03:53:07,855 - INFO - >>training completed		| train loss=0.00015442841592556316, val loss=0.00015183983622329853
2024-06-08 03:53:07,855 - INFO - #目前最低損失: train=4.003762083781347e-05, val=3.995403247204243e-05
2024-06-08 03:53:07,855 - INFO - #目前最佳隱藏層神經元數量: train=13, val=13
2024-06-08 03:53:07,856 - INFO - #目前最佳參數:
-train:
W1=[[ 0.20837252  0.06753717]
 [-0.14296398  0.39497908]
 [ 0.22966747  0.16746228]
 [-0.20159043 -0.21830756]
 [-0.28510049  0.26181504]
 [ 0.13556011  0.252373  ]
 [ 0.24496298  0.72778247]
 [ 0.00887322  0.29709613]
 [ 0.97730384  0.28429714]
 [-0.10250484 -0.25886682]
 [-0.43313168  0.01686621]
 [ 0.21647284  0.21586387]
 [-0.1432577  -0.23417335]]
b1=[[ 1.80000587e-03]
 [ 7.17807295e-03]
 [ 6.25316935e-05]
 [ 2.83326832e-03]
 [-3.77557181e-03]
 [ 1.73117162e-03]
 [ 1.61267711e-04]
 [-3.02472406e-02]
 [-2.01592124e-03]
 [ 3.96751401e-04]
 [ 1.26292707e-03]
 [-7.65266609e-04]
 [-1.04935252e-03]]
W2=[[ 0.27029993  0.32827802  0.88220182 -0.34871437 -0.01006072  0.39729673
  -0.24379516  0.16694958 -0.18184862 -0.48123543 -0.71624928  0.57974472
  -0.7341613 ]]
b2=[[0.00211387]]
-val:
W1=[[ 0.20837252  0.06753717]
 [-0.14296398  0.39497908]
 [ 0.22966747  0.16746228]
 [-0.20159043 -0.21830756]
 [-0.28510049  0.26181504]
 [ 0.13556011  0.252373  ]
 [ 0.24496298  0.72778247]
 [ 0.00887322  0.29709613]
 [ 0.97730384  0.28429714]
 [-0.10250484 -0.25886682]
 [-0.43313168  0.01686621]
 [ 0.21647284  0.21586387]
 [-0.1432577  -0.23417335]]
b1=[[ 1.80000587e-03]
 [ 7.17807295e-03]
 [ 6.25316935e-05]
 [ 2.83326832e-03]
 [-3.77557181e-03]
 [ 1.73117162e-03]
 [ 1.61267711e-04]
 [-3.02472406e-02]
 [-2.01592124e-03]
 [ 3.96751401e-04]
 [ 1.26292707e-03]
 [-7.65266609e-04]
 [-1.04935252e-03]]
W2=[[ 0.27029993  0.32827802  0.88220182 -0.34871437 -0.01006072  0.39729673
  -0.24379516  0.16694958 -0.18184862 -0.48123543 -0.71624928  0.57974472
  -0.7341613 ]]
b2=[[0.00211387]]

2024-06-08 03:53:07,858 - INFO - ----Hidden_size 18:
2024-06-08 03:53:07,858 - INFO - Round(1/30)
2024-06-08 03:53:18,446 - INFO - >>training completed		| train loss=0.00010578450393385362, val loss=0.00010568451806185551
2024-06-08 03:53:18,447 - INFO - Round(2/30)
2024-06-08 03:53:29,024 - INFO - >>training completed		| train loss=0.00010003425902003465, val loss=9.853007316491181e-05
2024-06-08 03:53:29,024 - INFO - Round(3/30)
2024-06-08 03:53:39,686 - INFO - >>training completed		| train loss=0.00015860459119835664, val loss=0.00015906420596169878
2024-06-08 03:53:39,686 - INFO - Round(4/30)
2024-06-08 03:53:50,110 - INFO - >>training completed		| train loss=0.00015913808699245663, val loss=0.00015505930653445275
2024-06-08 03:53:50,110 - INFO - Round(5/30)
2024-06-08 03:54:00,607 - INFO - >>training completed		| train loss=0.00011163095021293824, val loss=0.00011415817237778521
2024-06-08 03:54:00,607 - INFO - Round(6/30)
2024-06-08 03:54:11,170 - INFO - >>training completed		| train loss=9.272233836789697e-05, val loss=9.283664305444845e-05
2024-06-08 03:54:11,170 - INFO - Round(7/30)
2024-06-08 03:54:21,796 - INFO - >>training completed		| train loss=8.459252350742734e-05, val loss=8.564575587478449e-05
2024-06-08 03:54:21,797 - INFO - Round(8/30)
2024-06-08 03:54:32,539 - INFO - >>training completed		| train loss=0.00011907920599519934, val loss=0.00011651173453477717
2024-06-08 03:54:32,539 - INFO - Round(9/30)
2024-06-08 03:54:43,218 - INFO - >>training completed		| train loss=9.233969796699546e-05, val loss=9.350487335488657e-05
2024-06-08 03:54:43,218 - INFO - Round(10/30)
2024-06-08 03:54:53,959 - INFO - >>training completed		| train loss=0.00013483162068051845, val loss=0.00013240974509656181
2024-06-08 03:54:53,959 - INFO - Round(11/30)
2024-06-08 03:55:04,594 - INFO - >>training completed		| train loss=0.00019571523471224736, val loss=0.00018973349717820896
2024-06-08 03:55:04,594 - INFO - Round(12/30)
2024-06-08 03:55:15,185 - INFO - >>training completed		| train loss=0.00013786412310618542, val loss=0.00013762350533708177
2024-06-08 03:55:15,185 - INFO - Round(13/30)
2024-06-08 03:55:25,759 - INFO - >>training completed		| train loss=8.263674586795239e-05, val loss=8.13496085340262e-05
2024-06-08 03:55:25,759 - INFO - Round(14/30)
2024-06-08 03:55:36,329 - INFO - >>training completed		| train loss=5.353817757153615e-05, val loss=5.3205645846593575e-05
2024-06-08 03:55:36,330 - INFO - Round(15/30)
2024-06-08 03:55:46,836 - INFO - >>training completed		| train loss=0.00012460418763885305, val loss=0.00012599718107367543
2024-06-08 03:55:46,836 - INFO - Round(16/30)
2024-06-08 03:55:57,502 - INFO - >>training completed		| train loss=5.6137039632030894e-05, val loss=5.6879943689761956e-05
2024-06-08 03:55:57,503 - INFO - Round(17/30)
2024-06-08 03:56:08,092 - INFO - >>training completed		| train loss=9.229873385674974e-05, val loss=9.367598707651048e-05
2024-06-08 03:56:08,092 - INFO - Round(18/30)
2024-06-08 03:56:19,212 - INFO - >>training completed		| train loss=7.904568420699552e-05, val loss=7.806661454723913e-05
2024-06-08 03:56:19,212 - INFO - Round(19/30)
2024-06-08 03:56:30,399 - INFO - >>training completed		| train loss=0.0001281518307985215, val loss=0.00012663347369194284
2024-06-08 03:56:30,399 - INFO - Round(20/30)
2024-06-08 03:56:41,045 - INFO - >>training completed		| train loss=9.446384720740398e-05, val loss=9.29639362749555e-05
2024-06-08 03:56:41,045 - INFO - Round(21/30)
2024-06-08 03:56:51,560 - INFO - >>training completed		| train loss=0.00014652944178387205, val loss=0.00014487479659171742
2024-06-08 03:56:51,561 - INFO - Round(22/30)
2024-06-08 03:57:02,092 - INFO - >>training completed		| train loss=0.00010069844032600617, val loss=9.935336363843406e-05
2024-06-08 03:57:02,092 - INFO - Round(23/30)
2024-06-08 03:57:12,721 - INFO - >>training completed		| train loss=0.00019262356070236776, val loss=0.00018777173113834937
2024-06-08 03:57:12,721 - INFO - Round(24/30)
2024-06-08 03:57:23,885 - INFO - >>training completed		| train loss=6.975509088104299e-05, val loss=7.094787932351118e-05
2024-06-08 03:57:23,885 - INFO - Round(25/30)
2024-06-08 03:57:34,824 - INFO - >>training completed		| train loss=7.065643845979612e-05, val loss=7.079386392636519e-05
2024-06-08 03:57:34,824 - INFO - Round(26/30)
2024-06-08 03:57:45,988 - INFO - >>training completed		| train loss=0.00010666491913133908, val loss=0.00010790382507943481
2024-06-08 03:57:45,988 - INFO - Round(27/30)
2024-06-08 03:57:57,029 - INFO - >>training completed		| train loss=0.00021624496848846853, val loss=0.00021784957519903336
2024-06-08 03:57:57,030 - INFO - Round(28/30)
2024-06-08 03:58:08,336 - INFO - >>training completed		| train loss=5.149396075680736e-05, val loss=5.1859194782577355e-05
2024-06-08 03:58:08,336 - INFO - Round(29/30)
2024-06-08 03:58:19,360 - INFO - >>training completed		| train loss=0.0002329600678059012, val loss=0.00022573768900807385
2024-06-08 03:58:19,360 - INFO - Round(30/30)
2024-06-08 03:58:30,560 - INFO - >>training completed		| train loss=5.1705425284511506e-05, val loss=5.1081404105047474e-05
2024-06-08 03:58:30,560 - INFO - #目前最低損失: train=4.003762083781347e-05, val=3.995403247204243e-05
2024-06-08 03:58:30,561 - INFO - #目前最佳隱藏層神經元數量: train=13, val=13
2024-06-08 03:58:30,562 - INFO - #目前最佳參數:
-train:
W1=[[ 0.20837252  0.06753717]
 [-0.14296398  0.39497908]
 [ 0.22966747  0.16746228]
 [-0.20159043 -0.21830756]
 [-0.28510049  0.26181504]
 [ 0.13556011  0.252373  ]
 [ 0.24496298  0.72778247]
 [ 0.00887322  0.29709613]
 [ 0.97730384  0.28429714]
 [-0.10250484 -0.25886682]
 [-0.43313168  0.01686621]
 [ 0.21647284  0.21586387]
 [-0.1432577  -0.23417335]]
b1=[[ 1.80000587e-03]
 [ 7.17807295e-03]
 [ 6.25316935e-05]
 [ 2.83326832e-03]
 [-3.77557181e-03]
 [ 1.73117162e-03]
 [ 1.61267711e-04]
 [-3.02472406e-02]
 [-2.01592124e-03]
 [ 3.96751401e-04]
 [ 1.26292707e-03]
 [-7.65266609e-04]
 [-1.04935252e-03]]
W2=[[ 0.27029993  0.32827802  0.88220182 -0.34871437 -0.01006072  0.39729673
  -0.24379516  0.16694958 -0.18184862 -0.48123543 -0.71624928  0.57974472
  -0.7341613 ]]
b2=[[0.00211387]]
-val:
W1=[[ 0.20837252  0.06753717]
 [-0.14296398  0.39497908]
 [ 0.22966747  0.16746228]
 [-0.20159043 -0.21830756]
 [-0.28510049  0.26181504]
 [ 0.13556011  0.252373  ]
 [ 0.24496298  0.72778247]
 [ 0.00887322  0.29709613]
 [ 0.97730384  0.28429714]
 [-0.10250484 -0.25886682]
 [-0.43313168  0.01686621]
 [ 0.21647284  0.21586387]
 [-0.1432577  -0.23417335]]
b1=[[ 1.80000587e-03]
 [ 7.17807295e-03]
 [ 6.25316935e-05]
 [ 2.83326832e-03]
 [-3.77557181e-03]
 [ 1.73117162e-03]
 [ 1.61267711e-04]
 [-3.02472406e-02]
 [-2.01592124e-03]
 [ 3.96751401e-04]
 [ 1.26292707e-03]
 [-7.65266609e-04]
 [-1.04935252e-03]]
W2=[[ 0.27029993  0.32827802  0.88220182 -0.34871437 -0.01006072  0.39729673
  -0.24379516  0.16694958 -0.18184862 -0.48123543 -0.71624928  0.57974472
  -0.7341613 ]]
b2=[[0.00211387]]

2024-06-08 03:58:30,563 - INFO - ----Hidden_size 19:
2024-06-08 03:58:30,563 - INFO - Round(1/30)
2024-06-08 03:58:39,589 - INFO - >>early stopped at epoch 8	| train loss=0.00012563715148071177, val loss=0.00012497719133986774
2024-06-08 03:58:39,589 - INFO - Round(2/30)
2024-06-08 03:58:50,295 - INFO - >>training completed		| train loss=0.00010592871157036172, val loss=0.00010774701032819163
2024-06-08 03:58:50,296 - INFO - Round(3/30)
2024-06-08 03:59:01,156 - INFO - >>training completed		| train loss=8.520757610767818e-05, val loss=8.429495614745134e-05
2024-06-08 03:59:01,157 - INFO - Round(4/30)
2024-06-08 03:59:11,785 - INFO - >>training completed		| train loss=0.00015858842498643678, val loss=0.00015415566115585769
2024-06-08 03:59:11,785 - INFO - Round(5/30)
2024-06-08 03:59:22,450 - INFO - >>training completed		| train loss=0.00011925124758466792, val loss=0.00011667194496477302
2024-06-08 03:59:22,451 - INFO - Round(6/30)
2024-06-08 03:59:33,069 - INFO - >>training completed		| train loss=4.524273975906813e-05, val loss=4.5334383701259964e-05
2024-06-08 03:59:33,069 - INFO - Round(7/30)
2024-06-08 03:59:43,774 - INFO - >>training completed		| train loss=5.8833054872899414e-05, val loss=5.9467868357888564e-05
2024-06-08 03:59:43,775 - INFO - Round(8/30)
2024-06-08 03:59:54,254 - INFO - >>training completed		| train loss=0.00018271899809902268, val loss=0.00018089177611442723
2024-06-08 03:59:54,254 - INFO - Round(9/30)
2024-06-08 04:00:04,983 - INFO - >>training completed		| train loss=8.156069089557392e-05, val loss=8.323903283916591e-05
2024-06-08 04:00:04,983 - INFO - Round(10/30)
2024-06-08 04:00:15,628 - INFO - >>training completed		| train loss=4.783530347183914e-05, val loss=4.659663247513531e-05
2024-06-08 04:00:15,628 - INFO - Round(11/30)
2024-06-08 04:00:26,620 - INFO - >>training completed		| train loss=0.00011581223469158768, val loss=0.00011439404897561563
2024-06-08 04:00:26,620 - INFO - Round(12/30)
2024-06-08 04:00:37,174 - INFO - >>training completed		| train loss=0.00018963852072734723, val loss=0.0001823498738523201
2024-06-08 04:00:37,175 - INFO - Round(13/30)
2024-06-08 04:00:47,724 - INFO - >>training completed		| train loss=0.00012716497975436537, val loss=0.000127177336641993
2024-06-08 04:00:47,724 - INFO - Round(14/30)
2024-06-08 04:00:58,421 - INFO - >>training completed		| train loss=0.00016291302961309682, val loss=0.00016331230196019094
2024-06-08 04:00:58,421 - INFO - Round(15/30)
2024-06-08 04:01:09,102 - INFO - >>training completed		| train loss=8.378741128944477e-05, val loss=8.56764660261792e-05
2024-06-08 04:01:09,102 - INFO - Round(16/30)
2024-06-08 04:01:19,456 - INFO - >>training completed		| train loss=7.859854216962129e-05, val loss=7.888888642353983e-05
2024-06-08 04:01:19,456 - INFO - Round(17/30)
2024-06-08 04:01:29,921 - INFO - >>training completed		| train loss=8.99567673249208e-05, val loss=8.983097080916004e-05
2024-06-08 04:01:29,921 - INFO - Round(18/30)
2024-06-08 04:01:40,505 - INFO - >>training completed		| train loss=0.00011527502517698488, val loss=0.00011749692861576209
2024-06-08 04:01:40,505 - INFO - Round(19/30)
2024-06-08 04:01:50,981 - INFO - >>training completed		| train loss=0.0001423836116572063, val loss=0.0001406065902560005
2024-06-08 04:01:50,981 - INFO - Round(20/30)
2024-06-08 04:02:01,554 - INFO - >>training completed		| train loss=7.460969811901463e-05, val loss=7.313833067631266e-05
2024-06-08 04:02:01,554 - INFO - Round(21/30)
2024-06-08 04:02:12,100 - INFO - >>training completed		| train loss=6.787066602426757e-05, val loss=6.751391303025234e-05
2024-06-08 04:02:12,101 - INFO - Round(22/30)
2024-06-08 04:02:23,507 - INFO - >>training completed		| train loss=0.00010640134866195212, val loss=0.0001067327688857556
2024-06-08 04:02:23,507 - INFO - Round(23/30)
2024-06-08 04:02:34,965 - INFO - >>training completed		| train loss=9.826520983541023e-05, val loss=9.983574031777834e-05
2024-06-08 04:02:34,965 - INFO - Round(24/30)
2024-06-08 04:02:45,826 - INFO - >>training completed		| train loss=7.779144880691987e-05, val loss=7.73886124812656e-05
2024-06-08 04:02:45,826 - INFO - Round(25/30)
2024-06-08 04:02:56,434 - INFO - >>early stopped at epoch 10	| train loss=7.136526393570611e-05, val loss=7.153369513783287e-05
2024-06-08 04:02:56,435 - INFO - Round(26/30)
2024-06-08 04:03:06,888 - INFO - >>training completed		| train loss=9.523946375126073e-05, val loss=9.25495000106769e-05
2024-06-08 04:03:06,889 - INFO - Round(27/30)
2024-06-08 04:03:17,562 - INFO - >>training completed		| train loss=6.588173329188678e-05, val loss=6.480288410900063e-05
2024-06-08 04:03:17,562 - INFO - Round(28/30)
2024-06-08 04:03:28,918 - INFO - >>training completed		| train loss=0.00017686481369026653, val loss=0.0001753340059060035
2024-06-08 04:03:28,918 - INFO - Round(29/30)
2024-06-08 04:03:39,905 - INFO - >>training completed		| train loss=0.00012144954506587233, val loss=0.0001202779428056603
2024-06-08 04:03:39,905 - INFO - Round(30/30)
2024-06-08 04:03:50,471 - INFO - >>training completed		| train loss=0.00011247449868182234, val loss=0.00011215269840043214
2024-06-08 04:03:50,471 - INFO - #目前最低損失: train=4.003762083781347e-05, val=3.995403247204243e-05
2024-06-08 04:03:50,471 - INFO - #目前最佳隱藏層神經元數量: train=13, val=13
2024-06-08 04:03:50,472 - INFO - #目前最佳參數:
-train:
W1=[[ 0.20837252  0.06753717]
 [-0.14296398  0.39497908]
 [ 0.22966747  0.16746228]
 [-0.20159043 -0.21830756]
 [-0.28510049  0.26181504]
 [ 0.13556011  0.252373  ]
 [ 0.24496298  0.72778247]
 [ 0.00887322  0.29709613]
 [ 0.97730384  0.28429714]
 [-0.10250484 -0.25886682]
 [-0.43313168  0.01686621]
 [ 0.21647284  0.21586387]
 [-0.1432577  -0.23417335]]
b1=[[ 1.80000587e-03]
 [ 7.17807295e-03]
 [ 6.25316935e-05]
 [ 2.83326832e-03]
 [-3.77557181e-03]
 [ 1.73117162e-03]
 [ 1.61267711e-04]
 [-3.02472406e-02]
 [-2.01592124e-03]
 [ 3.96751401e-04]
 [ 1.26292707e-03]
 [-7.65266609e-04]
 [-1.04935252e-03]]
W2=[[ 0.27029993  0.32827802  0.88220182 -0.34871437 -0.01006072  0.39729673
  -0.24379516  0.16694958 -0.18184862 -0.48123543 -0.71624928  0.57974472
  -0.7341613 ]]
b2=[[0.00211387]]
-val:
W1=[[ 0.20837252  0.06753717]
 [-0.14296398  0.39497908]
 [ 0.22966747  0.16746228]
 [-0.20159043 -0.21830756]
 [-0.28510049  0.26181504]
 [ 0.13556011  0.252373  ]
 [ 0.24496298  0.72778247]
 [ 0.00887322  0.29709613]
 [ 0.97730384  0.28429714]
 [-0.10250484 -0.25886682]
 [-0.43313168  0.01686621]
 [ 0.21647284  0.21586387]
 [-0.1432577  -0.23417335]]
b1=[[ 1.80000587e-03]
 [ 7.17807295e-03]
 [ 6.25316935e-05]
 [ 2.83326832e-03]
 [-3.77557181e-03]
 [ 1.73117162e-03]
 [ 1.61267711e-04]
 [-3.02472406e-02]
 [-2.01592124e-03]
 [ 3.96751401e-04]
 [ 1.26292707e-03]
 [-7.65266609e-04]
 [-1.04935252e-03]]
W2=[[ 0.27029993  0.32827802  0.88220182 -0.34871437 -0.01006072  0.39729673
  -0.24379516  0.16694958 -0.18184862 -0.48123543 -0.71624928  0.57974472
  -0.7341613 ]]
b2=[[0.00211387]]

2024-06-08 04:03:50,474 - INFO - ----Hidden_size 20:
2024-06-08 04:03:50,474 - INFO - Round(1/30)
2024-06-08 04:04:00,988 - INFO - >>training completed		| train loss=0.00018499739180922897, val loss=0.00017755378444893625
2024-06-08 04:04:00,988 - INFO - Round(2/30)
2024-06-08 04:04:11,458 - INFO - >>training completed		| train loss=0.00013742029845936125, val loss=0.00013660980475331116
2024-06-08 04:04:11,458 - INFO - Round(3/30)
2024-06-08 04:04:22,434 - INFO - >>training completed		| train loss=7.853296413740063e-05, val loss=7.902920996360263e-05
2024-06-08 04:04:22,434 - INFO - Round(4/30)
2024-06-08 04:04:33,920 - INFO - >>training completed		| train loss=0.00011437333769823156, val loss=0.0001131247989279363
2024-06-08 04:04:33,920 - INFO - Round(5/30)
2024-06-08 04:04:44,654 - INFO - >>training completed		| train loss=9.09331260344882e-05, val loss=9.051195036472366e-05
2024-06-08 04:04:44,654 - INFO - Round(6/30)
2024-06-08 04:04:55,173 - INFO - >>training completed		| train loss=0.00011413203791221513, val loss=0.00011302995248875237
2024-06-08 04:04:55,173 - INFO - Round(7/30)
2024-06-08 04:05:05,777 - INFO - >>training completed		| train loss=0.00013698368298637107, val loss=0.00013530062004031681
2024-06-08 04:05:05,777 - INFO - Round(8/30)
2024-06-08 04:05:16,362 - INFO - >>training completed		| train loss=9.718087148703174e-05, val loss=9.876982410501035e-05
2024-06-08 04:05:16,362 - INFO - Round(9/30)
2024-06-08 04:05:26,884 - INFO - >>training completed		| train loss=6.817924889872911e-05, val loss=6.968380226553802e-05
2024-06-08 04:05:26,884 - INFO - Round(10/30)
2024-06-08 04:05:37,611 - INFO - >>training completed		| train loss=8.517270484809378e-05, val loss=8.550128182482874e-05
2024-06-08 04:05:37,611 - INFO - Round(11/30)
2024-06-08 04:05:48,163 - INFO - >>training completed		| train loss=0.000104898164636638, val loss=0.00010532637918815303
2024-06-08 04:05:48,163 - INFO - Round(12/30)
2024-06-08 04:05:58,794 - INFO - >>training completed		| train loss=4.096980905183989e-05, val loss=4.170430108896437e-05
2024-06-08 04:05:58,794 - INFO - Round(13/30)
2024-06-08 04:06:09,286 - INFO - >>training completed		| train loss=0.00010987960189864168, val loss=0.00010899098688580407
2024-06-08 04:06:09,286 - INFO - Round(14/30)
2024-06-08 04:06:19,953 - INFO - >>training completed		| train loss=0.00012298386113170166, val loss=0.0001196506449052335
2024-06-08 04:06:19,953 - INFO - Round(15/30)
2024-06-08 04:06:30,953 - INFO - >>training completed		| train loss=3.4476672121339074e-05, val loss=3.454288032783366e-05
2024-06-08 04:06:30,954 - INFO - Model saved to best_val_model.npz
2024-06-08 04:06:30,955 - INFO - Model saved to best_train_model.npz
2024-06-08 04:06:30,955 - INFO - Round(16/30)
2024-06-08 04:06:41,681 - INFO - >>training completed		| train loss=0.00011359609733200764, val loss=0.00011223735320017934
2024-06-08 04:06:41,681 - INFO - Round(17/30)
2024-06-08 04:06:52,248 - INFO - >>training completed		| train loss=5.335807375203183e-05, val loss=5.411731641194991e-05
2024-06-08 04:06:52,248 - INFO - Round(18/30)
2024-06-08 04:07:02,800 - INFO - >>training completed		| train loss=0.0001424127244994389, val loss=0.00013872056971911628
2024-06-08 04:07:02,801 - INFO - Round(19/30)
2024-06-08 04:07:13,355 - INFO - >>training completed		| train loss=8.084994910852457e-05, val loss=8.185520285757305e-05
2024-06-08 04:07:13,355 - INFO - Round(20/30)
2024-06-08 04:07:23,976 - INFO - >>training completed		| train loss=5.0229510065262044e-05, val loss=5.0944096053508353e-05
2024-06-08 04:07:23,976 - INFO - Round(21/30)
2024-06-08 04:07:34,624 - INFO - >>training completed		| train loss=7.237232750574796e-05, val loss=7.458958173752798e-05
2024-06-08 04:07:34,624 - INFO - Round(22/30)
2024-06-08 04:07:45,385 - INFO - >>training completed		| train loss=0.0001066382962558313, val loss=0.00010514357911180822
2024-06-08 04:07:45,385 - INFO - Round(23/30)
2024-06-08 04:07:55,836 - INFO - >>training completed		| train loss=7.435020111221125e-05, val loss=7.517429529905966e-05
2024-06-08 04:07:55,837 - INFO - Round(24/30)
2024-06-08 04:08:06,556 - INFO - >>training completed		| train loss=4.866611569790699e-05, val loss=4.884781871558116e-05
2024-06-08 04:08:06,556 - INFO - Round(25/30)
2024-06-08 04:08:18,362 - INFO - >>training completed		| train loss=7.979692287342058e-05, val loss=7.744638433401606e-05
2024-06-08 04:08:18,362 - INFO - Round(26/30)
2024-06-08 04:08:30,653 - INFO - >>training completed		| train loss=7.039959075238278e-05, val loss=7.050036331029502e-05
2024-06-08 04:08:30,654 - INFO - Round(27/30)
2024-06-08 04:08:42,391 - INFO - >>training completed		| train loss=7.000446890963416e-05, val loss=7.0643790437323e-05
2024-06-08 04:08:42,392 - INFO - Round(28/30)
2024-06-08 04:08:53,175 - INFO - >>training completed		| train loss=0.00017802433662958948, val loss=0.00017916706709147513
2024-06-08 04:08:53,175 - INFO - Round(29/30)
2024-06-08 04:09:03,834 - INFO - >>training completed		| train loss=7.049989870746778e-05, val loss=7.136286570879374e-05
2024-06-08 04:09:03,834 - INFO - Round(30/30)
2024-06-08 04:09:14,271 - INFO - >>training completed		| train loss=8.856411995200363e-05, val loss=9.02727639680073e-05
2024-06-08 04:09:14,272 - INFO - #目前最低損失: train=3.4476672121339074e-05, val=3.454288032783366e-05
2024-06-08 04:09:14,272 - INFO - #目前最佳隱藏層神經元數量: train=20, val=20
2024-06-08 04:09:14,273 - INFO - #目前最佳參數:
-train:
W1=[[-0.06380485 -0.30639931]
 [-0.40031421  0.07781777]
 [ 0.23027135 -0.66433441]
 [ 0.85793798  0.41741991]
 [-0.05204847  0.43438694]
 [-0.53806211  0.37097959]
 [ 0.27734785 -0.33229304]
 [-0.23961333 -0.17439609]
 [-0.3169097   0.10055499]
 [-0.02843852  0.85521217]
 [ 0.36252602 -0.0100315 ]
 [ 0.20375311  0.19697879]
 [ 0.19287169 -0.60679   ]
 [-0.04976506  0.44200605]
 [ 0.09980529 -0.49103865]
 [ 0.17734862  0.2213532 ]
 [-0.16033281 -0.20509269]
 [-0.58071374  0.18979206]
 [-1.08275352  0.18594549]
 [-0.1260957  -0.24488257]]
b1=[[ 4.45389702e-03]
 [-1.64478751e-03]
 [ 6.12165398e-04]
 [ 6.24072363e-04]
 [ 9.96011715e-04]
 [ 2.50784727e-03]
 [ 2.72344372e-03]
 [ 2.92061136e-03]
 [-2.16119461e-03]
 [-2.53523867e-03]
 [-5.18398806e-04]
 [ 6.37700782e-06]
 [-5.10491085e-05]
 [-4.44855275e-03]
 [ 1.96093891e-03]
 [ 2.57500832e-03]
 [-8.69024095e-05]
 [ 2.68191407e-03]
 [ 1.10502280e-03]
 [ 6.08384304e-03]]
W2=[[-0.15691855 -0.27283171 -0.1410835  -0.11212982  0.38901166 -0.01788928
   0.01775665 -0.62495076 -0.07910337 -0.40616659  0.60618133  0.48542477
  -0.12255365  0.35460828 -0.1822489   0.36021486 -0.86519852 -0.31517416
   0.15535277 -0.31644633]]
b2=[[0.00179353]]
-val:
W1=[[-0.06380485 -0.30639931]
 [-0.40031421  0.07781777]
 [ 0.23027135 -0.66433441]
 [ 0.85793798  0.41741991]
 [-0.05204847  0.43438694]
 [-0.53806211  0.37097959]
 [ 0.27734785 -0.33229304]
 [-0.23961333 -0.17439609]
 [-0.3169097   0.10055499]
 [-0.02843852  0.85521217]
 [ 0.36252602 -0.0100315 ]
 [ 0.20375311  0.19697879]
 [ 0.19287169 -0.60679   ]
 [-0.04976506  0.44200605]
 [ 0.09980529 -0.49103865]
 [ 0.17734862  0.2213532 ]
 [-0.16033281 -0.20509269]
 [-0.58071374  0.18979206]
 [-1.08275352  0.18594549]
 [-0.1260957  -0.24488257]]
b1=[[ 4.45389702e-03]
 [-1.64478751e-03]
 [ 6.12165398e-04]
 [ 6.24072363e-04]
 [ 9.96011715e-04]
 [ 2.50784727e-03]
 [ 2.72344372e-03]
 [ 2.92061136e-03]
 [-2.16119461e-03]
 [-2.53523867e-03]
 [-5.18398806e-04]
 [ 6.37700782e-06]
 [-5.10491085e-05]
 [-4.44855275e-03]
 [ 1.96093891e-03]
 [ 2.57500832e-03]
 [-8.69024095e-05]
 [ 2.68191407e-03]
 [ 1.10502280e-03]
 [ 6.08384304e-03]]
W2=[[-0.15691855 -0.27283171 -0.1410835  -0.11212982  0.38901166 -0.01788928
   0.01775665 -0.62495076 -0.07910337 -0.40616659  0.60618133  0.48542477
  -0.12255365  0.35460828 -0.1822489   0.36021486 -0.86519852 -0.31517416
   0.15535277 -0.31644633]]
b2=[[0.00179353]]

2024-06-08 04:09:14,275 - INFO - ----最佳隱藏層神經元數量: train=20, val=20
